{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fc4e7ec-3233-4b8a-8c68-618c36e753b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score, roc_curve, auc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset, Subset, SubsetRandomSampler\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.models as models\n",
    "from torchvision import models\n",
    "import timm\n",
    "import csv\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import copy\n",
    "import random\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR, LambdaLR, ExponentialLR, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fdcda54-5505-422e-a835-442c23d01d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 设置随机数种子，保证结果的可重复性\n",
    "random.seed(2024)\n",
    "np.random.seed(2024)\n",
    "torch.manual_seed(2024)\n",
    "torch.cuda.manual_seed(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1f10b2c-123f-4382-8140-1bcdc03a5242",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Load pretrained Swin Transformer model\n",
    "model = models.inception_v3(pretrained=False)\n",
    "# print(model)\n",
    "# for name, module in model.named_modules():\n",
    "#     # if name == 'norm' or name == 'head':\n",
    "#     print(name)\n",
    "# model\n",
    "# summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8886452-99e0-4ed7-9c2c-965bd7d404fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 假设你的权重文件路径是'path_to_your_weights.pth'\n",
    "#weights_path = 'root/autodl-tmp/project/MedSAM-0.1/Resnet/01.pth'\n",
    "\n",
    "# 加载权重\n",
    "#model.load_state_dict(torch.load(weights_path))\n",
    "num_ftrs = model.fc.in_features \n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False #False：冻结模型的参数，也就是采用该模型已经训练好的原始参数。只需要训练我们自己定义的Linear层\n",
    "\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad == True: #False：冻结模型的参数，也就是采用该模型已经训练好的原始参数。只需要训练我们自己定义的Linear层\n",
    "#         print(name)\n",
    "#保持in_features不变，修改out_features=3\n",
    "model.fc = nn.Sequential(nn.Linear(num_ftrs,6),\n",
    "                            nn.LogSoftmax(dim=1))\n",
    "\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad == True: #False：冻结模型的参数，也就是采用该模型已经训练好的原始参数。只需要训练我们自己定义的Linear层\n",
    "#         print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6ced03d-4a9f-49e9-bbe1-50852739f06d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 模型初始的dropout层p值为0，修改dropout层的p值，防止过拟合\n",
    "# new_dropout = 0.0  # 设置为0.5，即50%的Dropout\n",
    "# # 遍历模型的参数，找到所有的Dropout层，并设置新的Dropout值\n",
    "# for name, module in model.named_modules():\n",
    "#     if isinstance(module, nn.Dropout):\n",
    "#         # print(name)\n",
    "#         module.p = new_dropout\n",
    "# model\n",
    "# for name, module in model.named_modules():\n",
    "#     # if name == 'norm' or name == 'head':\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32b10a3-5513-4931-8b70-a3fac5a41365",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_layer_names = [name for name, _ in model.named_parameters()] # model.named_modules() model.named_parameters()\n",
    "free_layer_names = all_layer_names[:]\n",
    "free_layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d6a877e-92d8-41b1-b538-c75d389e5452",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in Inceptionv3 model: 25124558\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from timm.models import create_model\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters()) # 模型的参数个数\n",
    "print(f\"Number of parameters in Inceptionv3 model: {num_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ddcacb6-50e6-4814-9516-035f5559fa1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# params_to_update = [] # 需要更新的层\n",
    "# for name, param in model.named_parameters():\n",
    "#     if name.find(\"layers.3\") == -1: # 当前层不含layer.3不更新权重\n",
    "#         param.requires_grad = False\n",
    "#     if name.find(\"layers.3\") == -1 and name not in ['norm.weight', 'norm.bias', 'head.weight', 'head.bias']: #  当前层不含layer.3且name不等于列表中的\n",
    "#         param.requires_grad = False\n",
    "#     else: # 后30层网络需要训练\n",
    "#         param.requires_grad = True # 手动设置，不然不会自动赋值\n",
    "#         params_to_update.append(param)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f30d78b-495d-466d-b596-db7d9205f99d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data preprocessing and augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)), # 调整形状\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), # 转成tensor格式\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     # transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5863ddd8-f023-4870-a05f-5469cfb41f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# transform = None\n",
    "data_dir = \"/root/autodl-tmp/project/MedSAM-0.1/data/MULTI_TUMOR_split\" # 数据存储的根目录\n",
    "\n",
    "# train_data = datasets.ImageFolder(os.path.join(data_dir, \"train\")) # 对训练数据做增强，增加LGG类型的数量\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=transform) # 不对训练数据做增强，使用focal loss解决不平衡问题\n",
    "val_data = datasets.ImageFolder(os.path.join(data_dir, \"val\"), transform=transform)\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, \"test\"), transform=transform)\n",
    "\n",
    "# train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "# train_data = train_loader.dataset[:1000]\n",
    "\n",
    "# 从训练集中划分0.2作为验证集\n",
    "# 划分训练集和验证集\n",
    "# val_size = int(0.2 * len(train_data))\n",
    "# train_size = len(train_data) - val_size\n",
    "\n",
    "# val_size = 1000\n",
    "# train_size = 6000\n",
    "# other_size = len(train_data) - train_size - val_size\n",
    "# print(train_size, val_size)\n",
    "# train_data, val_data = random_split(train_data, [train_size, val_size])\n",
    "# train_data, val_data, _ = random_split(train_data, [train_size, val_size, other_size]) # 训练数据集切分成训练集和验证集\n",
    "# print(len(train_data))\n",
    "batch_size=64\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=64)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=64)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbb7ce4b-7c79-4edf-8b76-1b1536664d68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 154, 158)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(val_data), len(test_data)#, len(augmented_dataset)\n",
    "# len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea1799c8-aedb-4f80-8870-6d0feb67d9fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载dataset中的每一项，统计其中的0和1数量，构造出targets数组\n",
    "targets = []\n",
    "loader = DataLoader(train_data, batch_size=1, shuffle=False, num_workers=64)\n",
    "for images, labels in loader:\n",
    "    targets.append(labels.item())\n",
    "    # print(labels)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70882207-dca8-4c63-ad5a-f43e8843e02a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276, 371)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.count(1), targets.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f50b1b14-fdaa-4836-8e64-823df30081f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 在次定义训练曲线绘制函数与混淆矩阵绘制函数\n",
    "def plot_train_curve(modal ,train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr):\n",
    "    # 传入的参数train acc; val acc; val auc; val f1; val r; val fpr; val tpr\n",
    "    plt.figure()\n",
    "    plt.plot(train_acc_history, label=\"Train Acc\")\n",
    "    plt.plot(val_acc_history, label=\"Val Acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./inde_train_curve_images/' + 'Acc_curve_of_' + modal + '.png') # 存储acc的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_auc_history, label=\"Val AUC\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./inde_train_curve_images/' + 'Auc_curve_of_' + modal + '.png') # 存储val auc的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_f1_history, label=\"Val F1\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./inde_train_curve_images/' + 'F1_curve_of_' + modal + '.png') # 存储val f1的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_r_history, label=\"Val Recall\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Recall\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./inde_train_curve_images/' + 'Recall_curve_of_' + modal + '.png') # 存储val recall的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(val_fpr, val_tpr, label=f'ROC curve (area = {val_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('./inde_train_curve_images/' + 'ROC_curve_of_' + modal + '.png') # 存储ROC\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_martix(kfold, y_true, y_pred): # 传入的是训练预测得到的标签与真实的标签\n",
    "    # Define class labels\n",
    "    labels = ['HGG','LGG', 'normal']  # 用您的实际类别标签替换... LGG表示低级别胶质瘤，HGG表示高级别胶质瘤\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure()\n",
    "    sns.heatmap(conf_mat, annot=True, fmt=\".0f\", cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted labels\")\n",
    "    plt.ylabel(\"True labels\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig('./inde_val_confusion_martix_figs/' + 'Confusion_martix_of_' + modal + '.png')\n",
    "    # plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40751fa4-3570-46fe-b776-f4361d5ad2cb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (AuxLogits): InceptionAux(\n",
       "    (conv0): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=6, bias=True)\n",
       "    (1): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set loss function and optimizer\n",
    "# 训练 验证 测试 基于scan划分，独立测试\n",
    "\n",
    "# 迁移训练的层的设置\n",
    "flair_model = copy.deepcopy(model) # 不同输入的模型结果需要分开存储\n",
    "flair_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c326939-7683-40cc-bb29-7727435fa2ba",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flair_params_to_update = [] # 需要更新的层\n",
    "\n",
    "# 只更新部分层\n",
    "for name, param in flair_model.named_parameters():\n",
    "    # free后30层\n",
    "    # if name.find(\"layers.3\") == -1: # 当前层不含layer.3不更新权重\n",
    "    #     param.requires_grad = False\n",
    "    # if name.find(\"layers.3\") == -1 and name not in ['norm.weight', 'norm.bias', 'head.weight', 'head.bias']: #  当前层不含layer.3且name不等于列表中的\n",
    "    #     param.requires_grad = False\n",
    "    # else: # 后30层网络需要训练\n",
    "    #     param.requires_grad = True # 手动设置，不然不会自动赋值\n",
    "    #     flair_params_to_update.append(param)  \n",
    "    \n",
    "    # free后2层\n",
    "    # if name not in ['norm.weight', 'norm.bias', 'head.weight', 'head.bias']: # 只训练最后几层\n",
    "    if name not in free_layer_names: # 只训练最后几层\n",
    "        param.requires_grad = False \n",
    "    else:\n",
    "        param.requires_grad = True # 手动设置，不然不会自动赋值\n",
    "        flair_params_to_update.append(param)\n",
    "        \n",
    "        \n",
    "# # 对需要更新的层，设置dropout防止过拟合\n",
    "# new_dropout = 0.5  # 设置为0.5，即50%的Dropout\n",
    "# # 遍历模型的参数，找到所有的Dropout层，并设置新的Dropout值\n",
    "# for name, module in flair_model.named_modules():\n",
    "#     # 修改后30层的dropout\n",
    "#     if name.find(\"layers.3\") == -1: # 当前层不含layer.3不更新权重\n",
    "#         pass\n",
    "#     if name.find(\"layers.3\") == -1 and name not in ['norm.weight', 'norm.bias', 'head.weight', 'head.bias']: #  当前层不含layer.3且name不等于列表中的\n",
    "#         pass\n",
    "#     else: # 后30层网络需要训练\n",
    "#         if isinstance(module, nn.Dropout):\n",
    "#             # print(name)\n",
    "#             module.p = new_dropout\n",
    "# flair_model\n",
    "len(flair_params_to_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56f6a5a9-4f1e-4a77-9dd7-643d6e368eba",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "alpha = torch.tensor([3.0, 1.0])\n",
    "# print(type(alpha))\n",
    "# criterion = FocalLoss(alpha=[3.0, 1.0], gamma=2) # 自定义的focal loss\n",
    "# criterion = nn.BCELoss()\n",
    "# optimizer = optim.Adam(flair_model.parameters(), lr=5e-3)\n",
    "optimizer = optim.Adam(flair_params_to_update, lr=5e-3)\n",
    "\n",
    "# # 学习率动态变化\n",
    "# dynamic_lr = CosineAnnealingLR(optimizer, T_max=10)\n",
    "# print(\"初始化的学习率：\",optimizer.defaults['lr'])\n",
    "\n",
    "# lr_list = []\n",
    "# for epoch in range(1,101):\n",
    "#     optimizer.zero_grad()\n",
    "#     optimizer.step()\n",
    "#     print(\"第%d个epoch的学习率：%f\" % (epoch, optimizer.param_groups[0]['lr']))\n",
    "#     lr_list.append(optimizer.param_groups[0]['lr'])\n",
    "#     dynamic_lr.step()\n",
    "    \n",
    "# #画出epoch的变化图\n",
    "# plt.plot(list(range(1,101)),lr_list)\n",
    "# plt.xlabel(\"epoch\")\n",
    "# plt.ylabel(\"lr\")\n",
    "# plt.title(\"learning rate curve !\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18a80558-9ca4-49e0-bc1a-c47aa0941edc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m train_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     20\u001b[0m train_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     23\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m# 图像与标签\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[15], line 21\u001b[0m, in \u001b[0;36mAugmentedDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     19\u001b[0m     image, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_dataset[idx]\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m---> 21\u001b[0m         image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image, label\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m idx \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_dataset) \u001b[38;5;129;01mand\u001b[39;00m idx \u001b[38;5;241m<\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_dataset) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_target_samples): \u001b[38;5;66;03m# 水平翻转增强\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# 随机选择一个目标类别的图像\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torchvision/transforms/functional.py:140\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    138\u001b[0m     _log_api_usage_once(to_tensor)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (F_pil\u001b[38;5;241m.\u001b[39m_is_pil_image(pic) \u001b[38;5;129;01mor\u001b[39;00m _is_numpy(pic)):\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpic should be PIL Image or ndarray. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(pic)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_numpy(pic) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_numpy_image(pic):\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpic should be 2/3 dimensional. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpic\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>"
     ]
    }
   ],
   "source": [
    "# Training and validation\n",
    "num_epochs = 500\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "val_auc_history = []\n",
    "val_f1_history = []\n",
    "val_r_history = []\n",
    "\n",
    "min_loss = float('inf') # 初始min_loss无穷大\n",
    "best_acc = 0.0\n",
    "best_auc = 0.0\n",
    "patience = 30 # patience原来设成80，设为30当连续20个epoch不再下降时，改变学习率\n",
    "early_stop = patience\n",
    "change_rate = 15 # 多少个epoch不发生提升时，改变学习率\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    flair_model.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device) # 图像与标签\n",
    "        optimizer.zero_grad()\n",
    "        outputs = flair_model(images)\n",
    "        loss = criterion(outputs[0], labels)        \n",
    "       # loss = criterion(outputs, labels) # 交叉熵损失函数集成了softmax，直接将模型的输出当成参数传入即可，不需要额外的softmax操作（否则报错）\n",
    "        # print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # _, predicted = torch.max(outputs, 1)\n",
    "        predicted = torch.argmax(outputs[0], 1) # argmax获得标签，用于计算acc等指标\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    # 调整学习率, 一个epoch结束后调整学习率\n",
    "    # print('current epoch lr:', optimizer.param_groups[0]['lr'])\n",
    "    # dynamic_lr.step()\n",
    "    lr = optimizer.param_groups[0]['lr'] # 当前epoch的学习率\n",
    "    # 当early stop连续20次指标不再上升时，改变学习率\n",
    "    if early_stop < (patience - change_rate):\n",
    "        lr -= lr / (change_rate + early_stop)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        print ('Decay learning rate to lr: {}.'.format(lr))\n",
    "    \n",
    "    train_acc = train_correct / train_total\n",
    "    train_acc_history.append(train_acc)\n",
    "\n",
    "    \n",
    "    # Validation\n",
    "    flair_model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_outputs_list = []\n",
    "    val_labels_list = []\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = flair_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # _, predicted = torch.max(outputs, 1)\n",
    "            predicted = torch.argmax(outputs, 1)\n",
    "    \n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_outputs_list.append(outputs.cpu().numpy())\n",
    "            val_labels_list.append(labels.cpu().numpy())\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_acc_history.append(val_acc)\n",
    "\n",
    "        val_outputs = np.concatenate(val_outputs_list, axis=0)\n",
    "        val_labels = np.concatenate(val_labels_list, axis=0)\n",
    "\n",
    "        val_fpr, val_tpr, _ = roc_curve(val_labels, val_outputs[:, 1], pos_label=1) # 计算auc，val_outputs[:, 1]表示对正类别的预测概率\n",
    "        val_auc = auc(val_fpr, val_tpr)\n",
    "        val_auc_history.append(val_auc)\n",
    "\n",
    "        val_f1 = f1_score(val_labels, np.argmax(val_outputs, axis=1),average='weighted')\n",
    "        val_f1_history.append(val_f1)\n",
    "\n",
    "        val_r = recall_score(val_labels, np.argmax(val_outputs, axis=1),average='weighted')\n",
    "        val_r_history.append(val_r)\n",
    "\n",
    "        # Calculate average validation loss\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        # 得到验证集的平均损失\n",
    "        # 设置早停点\n",
    "        # if min_loss > avg_val_loss:\n",
    "        if best_acc < val_acc: # 以auc值最大存储最佳模型\n",
    "            # min_loss = avg_val_loss\n",
    "            best_acc = val_acc\n",
    "            early_stop = patience\n",
    "            model_name = 'flair_model_c3.pth' # 损失值最小的时候设置成最佳模型\n",
    "            torch.save(flair_model.state_dict(), model_name)\n",
    "        else: # 当前的平均损失比之前epoch的要大\n",
    "            early_stop -= 1\n",
    "        \n",
    "        # 当early_stop为0时，结束epoch训练\n",
    "        if early_stop == 0:\n",
    "            break\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}, Val F1: {val_f1:.4f}, Val Recall: {val_r:.4f}, Val Loss: {avg_val_loss:.4f}, Early Stop: {early_stop:.0f}\")\n",
    "        \n",
    "\n",
    "plot_train_curve('flair', train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68e1612d-705e-4ad9-98c9-05117f40a86c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(model.state_dict(), \"swin_model_brat_cls_2024_4_21.pth\") # 存储模型\n",
    "flair_model.load_state_dict(torch.load(\"flair_model_c3.pth\")) # 加载训练阶段存储的最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c859d144-6ad9-4a0e-b2aa-c3c572f2d56b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_train_curve('flair', train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "339f1fdc-f721-4f88-9f79-3deb519be738",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_train_curve('flair', train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33d92fc8-aba1-49a6-a606-7b58da2659cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, f1_score, recall_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "170edb83-063b-48a9-aaa2-5691cce34362",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9747, F1 Score: 0.9746, Recall: 0.9747\n"
     ]
    }
   ],
   "source": [
    "# Create a data loader for the images\n",
    "import torch.nn.functional as F\n",
    "data_dir = \"/root/autodl-tmp/project/MedSAM-0.1/data/MULTI_TUMOR_split/test\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "image_data = datasets.ImageFolder(data_dir, transform=transform)\n",
    "data_loader = DataLoader(image_data, batch_size=1, shuffle=False)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = flair_model(images)\n",
    "        probabilities = F.softmax(outputs, dim=1)  # 使用softmax函数进行概率化处理\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.append(labels.item())\n",
    "        y_pred.append(predicted.item())\n",
    "        y_scores.append(probabilities.cpu().numpy())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "y_scores = np.concatenate(y_scores, axis=0)\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "#auc_score = roc_auc_score(y_true, y_scores[:, 2], multi_class='ovo')\n",
    "f1 = f1_score(y_true, y_pred,average='weighted')\n",
    "recall = recall_score(y_true, y_pred,average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}, F1 Score: {f1:.4f}, Recall: {recall:.4f}\")#AUC: {auc_score:.4f}, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a380bc6-472c-4550-96e1-d5c9959b143b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        46\n",
      "           1       0.97      0.94      0.96        35\n",
      "           2       1.00      1.00      1.00        28\n",
      "           3       0.94      1.00      0.97        17\n",
      "           4       1.00      1.00      1.00        16\n",
      "           5       0.94      1.00      0.97        16\n",
      "\n",
      "    accuracy                           0.97       158\n",
      "   macro avg       0.97      0.98      0.98       158\n",
      "weighted avg       0.98      0.97      0.97       158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3d9406f-1473-480b-9e14-8ada00383ec8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Define class labels\n",
    "labels = ['Glioma','Meningioma', 'Neurocitoma', 'NORMAL', 'Outros', 'Schwannoma']  # 用您的实际类别标签替换...\n",
    "\n",
    "# Plot confusion matrix\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "plt.figure()\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\".0f\", cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
