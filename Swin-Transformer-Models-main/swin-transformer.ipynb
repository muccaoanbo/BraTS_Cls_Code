{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fc4e7ec-3233-4b8a-8c68-618c36e753b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score, roc_curve, auc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset, Subset, SubsetRandomSampler\n",
    "from torchvision import transforms, datasets\n",
    "import timm\n",
    "import csv\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import copy\n",
    "import random\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR, LambdaLR, ExponentialLR, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fdcda54-5505-422e-a835-442c23d01d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 设置随机数种子，保证结果的可重复性\n",
    "random.seed(2024)\n",
    "np.random.seed(2024)\n",
    "torch.manual_seed(2024)\n",
    "torch.cuda.manual_seed(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1f10b2c-123f-4382-8140-1bcdc03a5242",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SwinTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (layers): Sequential(\n",
       "    (0): BasicLayer(\n",
       "      (blocks): Sequential(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.009)\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicLayer(\n",
       "      (blocks): Sequential(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.018)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.027)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): BasicLayer(\n",
       "      (blocks): Sequential(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.036)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.045)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.055)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.064)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.073)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.082)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): BasicLayer(\n",
       "      (blocks): Sequential(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.091)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.100)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# nn.AdaptiveAvgPool1d\n",
    "# Load pretrained Swin Transformer model\n",
    "model = timm.create_model(\"swin_tiny_patch4_window7_224\", pretrained=False, num_classes=2).to(device) # 构建模型，并修改成2分类问题\n",
    "# print(model)\n",
    "# for name, module in model.named_modules():\n",
    "#     # if name == 'norm' or name == 'head':\n",
    "#     print(name)\n",
    "model\n",
    "# summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8886452-99e0-4ed7-9c2c-965bd7d404fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained model's state dictionary\n",
    "pretrained_model_path = \"swin_tiny_patch4_window7_224_22k.pth\" # swin_tiny_patch4_window7_224_22k.pth swin_tiny_patch4_window7_224_22kto1k_finetune.pth\n",
    "pretrained_state_dict = torch.load(pretrained_model_path, map_location=torch.device('cuda'))['model']\n",
    "# print(pretrained_state_dict)\n",
    "# Print model structure\n",
    "# for key in pretrained_state_dict.keys(): # 输出预训练模型的健\n",
    "#     print(key)\n",
    "\n",
    "# Change the output layer's weights and biases to match your model's output layer size\n",
    "pretrained_state_dict['head.weight'] = pretrained_state_dict['head.weight'][:6, :]\n",
    "pretrained_state_dict['head.bias'] = pretrained_state_dict['head.bias'][:6]\n",
    "\n",
    "# Load the modified state dictionary into your model\n",
    "model.load_state_dict(pretrained_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ced03d-4a9f-49e9-bbe1-50852739f06d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 模型初始的dropout层p值为0，修改dropout层的p值，防止过拟合\n",
    "# new_dropout = 0.0  # 设置为0.5，即50%的Dropout\n",
    "# # 遍历模型的参数，找到所有的Dropout层，并设置新的Dropout值\n",
    "# for name, module in model.named_modules():\n",
    "#     if isinstance(module, nn.Dropout):\n",
    "#         # print(name)\n",
    "#         module.p = new_dropout\n",
    "# model\n",
    "# for name, module in model.named_modules():\n",
    "#     # if name == 'norm' or name == 'head':\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b32b10a3-5513-4931-8b70-a3fac5a41365",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['layers.3.blocks.0.mlp.fc1.bias',\n",
       " 'layers.3.blocks.0.mlp.fc2.weight',\n",
       " 'layers.3.blocks.0.mlp.fc2.bias',\n",
       " 'layers.3.blocks.1.norm1.weight',\n",
       " 'layers.3.blocks.1.norm1.bias',\n",
       " 'layers.3.blocks.1.attn.relative_position_bias_table',\n",
       " 'layers.3.blocks.1.attn.qkv.weight',\n",
       " 'layers.3.blocks.1.attn.qkv.bias',\n",
       " 'layers.3.blocks.1.attn.proj.weight',\n",
       " 'layers.3.blocks.1.attn.proj.bias',\n",
       " 'layers.3.blocks.1.norm2.weight',\n",
       " 'layers.3.blocks.1.norm2.bias',\n",
       " 'layers.3.blocks.1.mlp.fc1.weight',\n",
       " 'layers.3.blocks.1.mlp.fc1.bias',\n",
       " 'layers.3.blocks.1.mlp.fc2.weight',\n",
       " 'layers.3.blocks.1.mlp.fc2.bias',\n",
       " 'norm.weight',\n",
       " 'norm.bias',\n",
       " 'head.weight',\n",
       " 'head.bias']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_layer_names = [name for name, _ in model.named_parameters()] # model.named_modules() model.named_parameters()\n",
    "free_layer_names = all_layer_names[-20:]\n",
    "free_layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d6a877e-92d8-41b1-b538-c75d389e5452",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in SwinTransformer model: 27520892\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from timm.models import create_model\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters()) # 模型的参数个数\n",
    "print(f\"Number of parameters in SwinTransformer model: {num_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f30d78b-495d-466d-b596-db7d9205f99d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data preprocessing and augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # 调整形状\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), # 转成tensor格式\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     # transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5863ddd8-f023-4870-a05f-5469cfb41f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# transform = None\n",
    "data_dir = \"/root/autodl-tmp/project/MedSAM-0.1/data/MULTI_TUMOR_split\" # 数据存储的根目录\n",
    "\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, \"train\")) # 对训练数据做增强，增加LGG类型的数量\n",
    "# train_data = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=transform) # 不对训练数据做增强，使用focal loss解决不平衡问题\n",
    "val_data = datasets.ImageFolder(os.path.join(data_dir, \"val\"), transform=transform)\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, \"test\"), transform=transform)\n",
    "\n",
    "# train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "# train_data = train_loader.dataset[:1000]\n",
    "\n",
    "# 从训练集中划分0.2作为验证集\n",
    "# 划分训练集和验证集\n",
    "# val_size = int(0.2 * len(train_data))\n",
    "# train_size = len(train_data) - val_size\n",
    "\n",
    "# val_size = 1000\n",
    "# train_size = 6000\n",
    "# other_size = len(train_data) - train_size - val_size\n",
    "# print(train_size, val_size)\n",
    "# train_data, val_data = random_split(train_data, [train_size, val_size])\n",
    "# train_data, val_data, _ = random_split(train_data, [train_size, val_size, other_size]) # 训练数据集切分成训练集和验证集\n",
    "# print(len(train_data))\n",
    "batch_size=64\n",
    "# train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=64)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=64)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b79471d5-0d48-4d6c-9732-09bbb09e806d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11992\n",
      "2558\n"
     ]
    }
   ],
   "source": [
    "# 增加LGG的数量，因为训练中HGG与LGG的比例差不多为3.69:1\n",
    "class AugmentedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, original_dataset, target_class, transform=None):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.target_class = target_class\n",
    "        self.transform = transform\n",
    "\n",
    "        # 获取目标类别的图像索引\n",
    "        self.target_indices = [index for index, (image, label) in enumerate(original_dataset) if label == target_class]\n",
    "        self.num_target_samples = len(self.target_indices)\n",
    "        print(len(original_dataset))\n",
    "        print(self.num_target_samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.original_dataset) + 2 * self.num_target_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self.original_dataset):\n",
    "            image, label = self.original_dataset[idx]\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "        elif idx >= len(self.original_dataset) and idx < (len(self.original_dataset) + self.num_target_samples): # 水平翻转增强\n",
    "            # 随机选择一个目标类别的图像\n",
    "            random_index = self.target_indices[idx - len(self.original_dataset)]\n",
    "            image, label = self.original_dataset[random_index]\n",
    "            # 对该图像进行随机水平翻转\n",
    "            if self.transform:\n",
    "                image = transforms.RandomHorizontalFlip()(image)\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "        else: # 垂直翻转增强\n",
    "            # 随机选择一个目标类别的图像\n",
    "            random_index = self.target_indices[idx - len(self.original_dataset) - self.num_target_samples]\n",
    "            image, label = self.original_dataset[random_index]\n",
    "            # 对该图像进行随机垂直翻转\n",
    "            if self.transform:\n",
    "                image = transforms.RandomVerticalFlip()(image)\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "# 定义要增强的目标类别\n",
    "target_class = 0  # 假设要增强第1类的数据\n",
    "# 构建增强后的数据集\n",
    "augmented_dataset = AugmentedDataset(train_data, target_class, transform=transform) # 增加训练数据集中的hgg与lgg的比例\n",
    "# 加载数据集\n",
    "aug_train_data = DataLoader(augmented_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_loader = aug_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbb7ce4b-7c79-4edf-8b76-1b1536664d68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11992, 3904, 4007, 17108)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(val_data), len(test_data), len(augmented_dataset)\n",
    "# len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea1799c8-aedb-4f80-8870-6d0feb67d9fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载dataset中的每一项，统计其中的0和1数量，构造出targets数组\n",
    "targets = []\n",
    "loader = DataLoader(augmented_dataset, batch_size=1, shuffle=False, num_workers=64)\n",
    "for images, labels in loader:\n",
    "    targets.append(labels.item())\n",
    "    # print(labels)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70882207-dca8-4c63-ad5a-f43e8843e02a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9434, 7674)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.count(1), targets.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "94a3b6c0-00b6-42e5-adbf-0dcb768b5b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "350e1518-120a-4fca-a2ac-570d698aedf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义focal loss，解决数据不均衡的问题\n",
    "import torch.nn.functional as F\n",
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction # 损失函数的形式\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        # focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
    "        focal_loss = (1-pt)**self.gamma * ce_loss\n",
    "        # focal_loss.to(device)\n",
    "        # print(focal_loss)\n",
    "        \n",
    "        # 给予不同类别不同的权重\n",
    "        if self.alpha is not None:\n",
    "            # print('hello')\n",
    "            # print(targets)\n",
    "            targets_cpu = targets.detach().cpu().numpy()\n",
    "            # print(self.alpha.type())\n",
    "            # print(inputs.data.type())\n",
    "            # if self.alpha.type() != inputs.data.type():\n",
    "                # self.alpha = self.alpha.type_as(inputs.data)\n",
    "            alpha_factor = np.array(self.alpha)[targets_cpu]\n",
    "            alpha_factor = torch.tensor(alpha_factor)\n",
    "            alpha_factor = alpha_factor.to(device)\n",
    "            # print(alpha_factor)\n",
    "            focal_loss = alpha_factor * focal_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(focal_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(focal_loss)\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f50b1b14-fdaa-4836-8e64-823df30081f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 在次定义训练曲线绘制函数与混淆矩阵绘制函数\n",
    "def plot_train_curve(modal ,train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr):\n",
    "    # 传入的参数train acc; val acc; val auc; val f1; val r; val fpr; val tpr\n",
    "    plt.figure()\n",
    "    plt.plot(train_acc_history, label=\"Train Acc\")\n",
    "    plt.plot(val_acc_history, label=\"Val Acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./inde_train_curve_images/' + 'Acc_curve_of_' + modal + '.png') # 存储acc的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_auc_history, label=\"Val AUC\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./inde_train_curve_images/' + 'Auc_curve_of_' + modal + '.png') # 存储val auc的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_f1_history, label=\"Val F1\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./inde_train_curve_images/' + 'F1_curve_of_' + modal + '.png') # 存储val f1的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_r_history, label=\"Val Recall\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Recall\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./inde_train_curve_images/' + 'Recall_curve_of_' + modal + '.png') # 存储val recall的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(val_fpr, val_tpr, label=f'ROC curve (area = {val_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('./inde_train_curve_images/' + 'ROC_curve_of_' + modal + '.png') # 存储ROC\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_martix(kfold, y_true, y_pred): # 传入的是训练预测得到的标签与真实的标签\n",
    "    # Define class labels\n",
    "    labels = ['HGG','LGG']  # 用您的实际类别标签替换... LGG表示低级别胶质瘤，HGG表示高级别胶质瘤\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure()\n",
    "    sns.heatmap(conf_mat, annot=True, fmt=\".0f\", cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted labels\")\n",
    "    plt.ylabel(\"True labels\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig('./inde_val_confusion_martix_figs/' + 'Confusion_martix_of_' + modal + '.png')\n",
    "    # plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62d5dc64-39f2-4330-acff-ea5e731456fe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set loss function and optimizer\n",
    "# 训练 验证 测试 基于scan划分，独立测试\n",
    "\n",
    "# 迁移训练的层的设置\n",
    "flair_model = copy.deepcopy(model) # 不同输入的模型结果需要分开存储\n",
    "flair_model.to(device)\n",
    "flair_params_to_update = [] # 需要更新的层\n",
    "\n",
    "# 只更新部分层\n",
    "for name, param in flair_model.named_parameters():\n",
    "    # free后30层\n",
    "    # if name.find(\"layers.3\") == -1: # 当前层不含layer.3不更新权重\n",
    "    #     param.requires_grad = False\n",
    "    # if name.find(\"layers.3\") == -1 and name not in ['norm.weight', 'norm.bias', 'head.weight', 'head.bias']: #  当前层不含layer.3且name不等于列表中的\n",
    "    #     param.requires_grad = False\n",
    "    # else: # 后30层网络需要训练\n",
    "    #     param.requires_grad = True # 手动设置，不然不会自动赋值\n",
    "    #     flair_params_to_update.append(param)  \n",
    "    \n",
    "    # free后2层\n",
    "    # if name not in ['norm.weight', 'norm.bias', 'head.weight', 'head.bias']: # 只训练最后几层\n",
    "    if name not in free_layer_names: # 只训练最后几层\n",
    "        param.requires_grad = False \n",
    "    else:\n",
    "        param.requires_grad = True # 手动设置，不然不会自动赋值\n",
    "        flair_params_to_update.append(param)\n",
    "        \n",
    "        \n",
    "# # 对需要更新的层，设置dropout防止过拟合\n",
    "# new_dropout = 0.5  # 设置为0.5，即50%的Dropout\n",
    "# # 遍历模型的参数，找到所有的Dropout层，并设置新的Dropout值\n",
    "# for name, module in flair_model.named_modules():\n",
    "#     # 修改后30层的dropout\n",
    "#     if name.find(\"layers.3\") == -1: # 当前层不含layer.3不更新权重\n",
    "#         pass\n",
    "#     if name.find(\"layers.3\") == -1 and name not in ['norm.weight', 'norm.bias', 'head.weight', 'head.bias']: #  当前层不含layer.3且name不等于列表中的\n",
    "#         pass\n",
    "#     else: # 后30层网络需要训练\n",
    "#         if isinstance(module, nn.Dropout):\n",
    "#             # print(name)\n",
    "#             module.p = new_dropout\n",
    "# flair_model\n",
    "len(flair_params_to_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56f6a5a9-4f1e-4a77-9dd7-643d6e368eba",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "alpha = torch.tensor([3.0, 1.0])\n",
    "# print(type(alpha))\n",
    "# criterion = FocalLoss(alpha=[3.0, 1.0], gamma=2) # 自定义的focal loss\n",
    "# criterion = nn.BCELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "optimizer = optim.Adam(flair_params_to_update, lr=1e-4)\n",
    "# 学习率动态变化\n",
    "# dynamic_lr = CosineAnnealingLR(optimizer, T_max=5)\n",
    "# print(\"初始化的学习率：\",optimizer.defaults['lr'])\n",
    "\n",
    "# lr_list = []\n",
    "# for epoch in range(1,101):\n",
    "#     optimizer.zero_grad()\n",
    "#     optimizer.step()\n",
    "#     print(\"第%d个epoch的学习率：%f\" % (epoch, optimizer.param_groups[0]['lr']))\n",
    "#     lr_list.append(optimizer.param_groups[0]['lr'])\n",
    "#     dynamic_lr.step()\n",
    "    \n",
    "# #画出epoch的变化图\n",
    "# plt.plot(list(range(1,101)),lr_list)\n",
    "# plt.xlabel(\"epoch\")\n",
    "# plt.ylabel(\"lr\")\n",
    "# plt.title(\"learning rate curve !\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18a80558-9ca4-49e0-bc1a-c47aa0941edc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Train Acc: 0.8056, Val Acc: 0.8414, Val AUC: 0.9036, Val F1: 0.8456, Val Recall: 0.8414, Val Loss: 0.3653, Early Stop: 30\n",
      "Epoch 2/500, Train Acc: 0.9498, Val Acc: 0.8468, Val AUC: 0.8976, Val F1: 0.8458, Val Recall: 0.8468, Val Loss: 0.4887, Early Stop: 30\n",
      "Epoch 3/500, Train Acc: 0.9695, Val Acc: 0.8578, Val AUC: 0.9132, Val F1: 0.8553, Val Recall: 0.8578, Val Loss: 0.5067, Early Stop: 30\n",
      "Epoch 4/500, Train Acc: 0.9761, Val Acc: 0.8404, Val AUC: 0.9052, Val F1: 0.8435, Val Recall: 0.8404, Val Loss: 0.5934, Early Stop: 29\n",
      "Epoch 5/500, Train Acc: 0.9829, Val Acc: 0.8571, Val AUC: 0.9059, Val F1: 0.8540, Val Recall: 0.8571, Val Loss: 0.6330, Early Stop: 28\n",
      "Epoch 6/500, Train Acc: 0.9839, Val Acc: 0.8320, Val AUC: 0.8924, Val F1: 0.8353, Val Recall: 0.8320, Val Loss: 0.7211, Early Stop: 27\n",
      "Epoch 7/500, Train Acc: 0.9859, Val Acc: 0.8548, Val AUC: 0.8889, Val F1: 0.8525, Val Recall: 0.8548, Val Loss: 0.7324, Early Stop: 26\n",
      "Epoch 8/500, Train Acc: 0.9878, Val Acc: 0.8599, Val AUC: 0.9109, Val F1: 0.8611, Val Recall: 0.8599, Val Loss: 0.7031, Early Stop: 30\n",
      "Epoch 9/500, Train Acc: 0.9880, Val Acc: 0.8635, Val AUC: 0.9154, Val F1: 0.8627, Val Recall: 0.8635, Val Loss: 0.7634, Early Stop: 30\n",
      "Epoch 10/500, Train Acc: 0.9897, Val Acc: 0.8653, Val AUC: 0.9173, Val F1: 0.8644, Val Recall: 0.8653, Val Loss: 0.7086, Early Stop: 30\n",
      "Epoch 11/500, Train Acc: 0.9902, Val Acc: 0.8586, Val AUC: 0.9094, Val F1: 0.8527, Val Recall: 0.8586, Val Loss: 0.8632, Early Stop: 29\n",
      "Epoch 12/500, Train Acc: 0.9894, Val Acc: 0.8627, Val AUC: 0.9036, Val F1: 0.8608, Val Recall: 0.8627, Val Loss: 0.8349, Early Stop: 28\n",
      "Epoch 13/500, Train Acc: 0.9921, Val Acc: 0.8660, Val AUC: 0.9069, Val F1: 0.8620, Val Recall: 0.8660, Val Loss: 0.7930, Early Stop: 30\n",
      "Epoch 14/500, Train Acc: 0.9918, Val Acc: 0.8568, Val AUC: 0.9022, Val F1: 0.8554, Val Recall: 0.8568, Val Loss: 0.8381, Early Stop: 29\n",
      "Epoch 15/500, Train Acc: 0.9923, Val Acc: 0.8637, Val AUC: 0.9139, Val F1: 0.8604, Val Recall: 0.8637, Val Loss: 0.8266, Early Stop: 28\n",
      "Epoch 16/500, Train Acc: 0.9906, Val Acc: 0.8671, Val AUC: 0.9091, Val F1: 0.8660, Val Recall: 0.8671, Val Loss: 0.9591, Early Stop: 30\n",
      "Epoch 17/500, Train Acc: 0.9911, Val Acc: 0.8594, Val AUC: 0.9149, Val F1: 0.8524, Val Recall: 0.8594, Val Loss: 0.9931, Early Stop: 29\n",
      "Epoch 18/500, Train Acc: 0.9933, Val Acc: 0.8681, Val AUC: 0.9126, Val F1: 0.8673, Val Recall: 0.8681, Val Loss: 0.9234, Early Stop: 30\n",
      "Epoch 19/500, Train Acc: 0.9927, Val Acc: 0.8683, Val AUC: 0.9151, Val F1: 0.8674, Val Recall: 0.8683, Val Loss: 0.9145, Early Stop: 30\n",
      "Epoch 20/500, Train Acc: 0.9932, Val Acc: 0.8653, Val AUC: 0.9134, Val F1: 0.8611, Val Recall: 0.8653, Val Loss: 1.0149, Early Stop: 29\n",
      "Epoch 21/500, Train Acc: 0.9929, Val Acc: 0.8537, Val AUC: 0.9061, Val F1: 0.8476, Val Recall: 0.8537, Val Loss: 0.9877, Early Stop: 28\n",
      "Epoch 22/500, Train Acc: 0.9930, Val Acc: 0.8653, Val AUC: 0.9156, Val F1: 0.8635, Val Recall: 0.8653, Val Loss: 0.9275, Early Stop: 27\n",
      "Epoch 23/500, Train Acc: 0.9940, Val Acc: 0.8653, Val AUC: 0.9128, Val F1: 0.8648, Val Recall: 0.8653, Val Loss: 0.8779, Early Stop: 26\n",
      "Epoch 24/500, Train Acc: 0.9920, Val Acc: 0.8532, Val AUC: 0.9079, Val F1: 0.8473, Val Recall: 0.8532, Val Loss: 0.8702, Early Stop: 25\n",
      "Epoch 25/500, Train Acc: 0.9942, Val Acc: 0.8642, Val AUC: 0.9158, Val F1: 0.8618, Val Recall: 0.8642, Val Loss: 0.9133, Early Stop: 24\n",
      "Epoch 26/500, Train Acc: 0.9933, Val Acc: 0.8473, Val AUC: 0.9025, Val F1: 0.8385, Val Recall: 0.8473, Val Loss: 1.0371, Early Stop: 23\n",
      "Epoch 27/500, Train Acc: 0.9944, Val Acc: 0.8530, Val AUC: 0.8987, Val F1: 0.8510, Val Recall: 0.8530, Val Loss: 0.9284, Early Stop: 22\n",
      "Epoch 28/500, Train Acc: 0.9943, Val Acc: 0.8663, Val AUC: 0.9051, Val F1: 0.8632, Val Recall: 0.8663, Val Loss: 0.9597, Early Stop: 21\n",
      "Epoch 29/500, Train Acc: 0.9938, Val Acc: 0.8671, Val AUC: 0.9145, Val F1: 0.8661, Val Recall: 0.8671, Val Loss: 0.8923, Early Stop: 20\n",
      "Epoch 30/500, Train Acc: 0.9943, Val Acc: 0.8714, Val AUC: 0.9137, Val F1: 0.8692, Val Recall: 0.8714, Val Loss: 0.8205, Early Stop: 30\n",
      "Epoch 31/500, Train Acc: 0.9947, Val Acc: 0.8548, Val AUC: 0.9072, Val F1: 0.8561, Val Recall: 0.8548, Val Loss: 1.0072, Early Stop: 29\n",
      "Epoch 32/500, Train Acc: 0.9948, Val Acc: 0.8573, Val AUC: 0.9176, Val F1: 0.8508, Val Recall: 0.8573, Val Loss: 0.9906, Early Stop: 28\n",
      "Epoch 33/500, Train Acc: 0.9965, Val Acc: 0.8509, Val AUC: 0.9010, Val F1: 0.8536, Val Recall: 0.8509, Val Loss: 1.1038, Early Stop: 27\n",
      "Epoch 34/500, Train Acc: 0.9951, Val Acc: 0.8683, Val AUC: 0.9215, Val F1: 0.8651, Val Recall: 0.8683, Val Loss: 0.8664, Early Stop: 26\n",
      "Epoch 35/500, Train Acc: 0.9935, Val Acc: 0.8568, Val AUC: 0.9082, Val F1: 0.8594, Val Recall: 0.8568, Val Loss: 0.8744, Early Stop: 25\n",
      "Epoch 36/500, Train Acc: 0.9960, Val Acc: 0.8730, Val AUC: 0.9138, Val F1: 0.8694, Val Recall: 0.8730, Val Loss: 1.0162, Early Stop: 30\n",
      "Epoch 37/500, Train Acc: 0.9958, Val Acc: 0.8650, Val AUC: 0.9040, Val F1: 0.8622, Val Recall: 0.8650, Val Loss: 1.1471, Early Stop: 29\n",
      "Epoch 38/500, Train Acc: 0.9948, Val Acc: 0.8676, Val AUC: 0.9127, Val F1: 0.8654, Val Recall: 0.8676, Val Loss: 1.0848, Early Stop: 28\n",
      "Epoch 39/500, Train Acc: 0.9956, Val Acc: 0.8586, Val AUC: 0.9154, Val F1: 0.8527, Val Recall: 0.8586, Val Loss: 1.1648, Early Stop: 27\n",
      "Epoch 40/500, Train Acc: 0.9956, Val Acc: 0.8691, Val AUC: 0.9187, Val F1: 0.8657, Val Recall: 0.8691, Val Loss: 0.9594, Early Stop: 26\n",
      "Epoch 41/500, Train Acc: 0.9956, Val Acc: 0.8681, Val AUC: 0.9189, Val F1: 0.8647, Val Recall: 0.8681, Val Loss: 0.9238, Early Stop: 25\n",
      "Epoch 42/500, Train Acc: 0.9950, Val Acc: 0.8722, Val AUC: 0.9245, Val F1: 0.8680, Val Recall: 0.8722, Val Loss: 0.8921, Early Stop: 24\n",
      "Epoch 43/500, Train Acc: 0.9957, Val Acc: 0.8663, Val AUC: 0.9243, Val F1: 0.8608, Val Recall: 0.8663, Val Loss: 0.8753, Early Stop: 23\n",
      "Epoch 44/500, Train Acc: 0.9955, Val Acc: 0.8671, Val AUC: 0.9151, Val F1: 0.8635, Val Recall: 0.8671, Val Loss: 1.1033, Early Stop: 22\n",
      "Epoch 45/500, Train Acc: 0.9958, Val Acc: 0.8770, Val AUC: 0.9183, Val F1: 0.8730, Val Recall: 0.8770, Val Loss: 0.9988, Early Stop: 30\n",
      "Epoch 46/500, Train Acc: 0.9956, Val Acc: 0.8773, Val AUC: 0.9172, Val F1: 0.8737, Val Recall: 0.8773, Val Loss: 1.0520, Early Stop: 30\n",
      "Epoch 47/500, Train Acc: 0.9963, Val Acc: 0.8770, Val AUC: 0.9225, Val F1: 0.8708, Val Recall: 0.8770, Val Loss: 1.1576, Early Stop: 29\n",
      "Epoch 48/500, Train Acc: 0.9942, Val Acc: 0.8717, Val AUC: 0.9183, Val F1: 0.8685, Val Recall: 0.8717, Val Loss: 1.1803, Early Stop: 28\n",
      "Epoch 49/500, Train Acc: 0.9958, Val Acc: 0.8668, Val AUC: 0.9150, Val F1: 0.8688, Val Recall: 0.8668, Val Loss: 1.0519, Early Stop: 27\n",
      "Epoch 50/500, Train Acc: 0.9965, Val Acc: 0.8694, Val AUC: 0.9199, Val F1: 0.8676, Val Recall: 0.8694, Val Loss: 1.0700, Early Stop: 26\n",
      "Epoch 51/500, Train Acc: 0.9961, Val Acc: 0.8714, Val AUC: 0.9161, Val F1: 0.8687, Val Recall: 0.8714, Val Loss: 1.1059, Early Stop: 25\n",
      "Epoch 52/500, Train Acc: 0.9967, Val Acc: 0.8599, Val AUC: 0.9125, Val F1: 0.8550, Val Recall: 0.8599, Val Loss: 1.1304, Early Stop: 24\n",
      "Epoch 53/500, Train Acc: 0.9954, Val Acc: 0.8694, Val AUC: 0.9093, Val F1: 0.8681, Val Recall: 0.8694, Val Loss: 0.8029, Early Stop: 23\n",
      "Epoch 54/500, Train Acc: 0.9964, Val Acc: 0.8640, Val AUC: 0.9150, Val F1: 0.8565, Val Recall: 0.8640, Val Loss: 0.9937, Early Stop: 22\n",
      "Epoch 55/500, Train Acc: 0.9963, Val Acc: 0.8719, Val AUC: 0.9188, Val F1: 0.8683, Val Recall: 0.8719, Val Loss: 1.0985, Early Stop: 21\n",
      "Epoch 56/500, Train Acc: 0.9970, Val Acc: 0.8712, Val AUC: 0.9152, Val F1: 0.8671, Val Recall: 0.8712, Val Loss: 1.0414, Early Stop: 20\n",
      "Epoch 57/500, Train Acc: 0.9961, Val Acc: 0.8727, Val AUC: 0.9130, Val F1: 0.8725, Val Recall: 0.8727, Val Loss: 1.0692, Early Stop: 19\n",
      "Epoch 58/500, Train Acc: 0.9967, Val Acc: 0.8627, Val AUC: 0.8959, Val F1: 0.8631, Val Recall: 0.8627, Val Loss: 1.1424, Early Stop: 18\n",
      "Epoch 59/500, Train Acc: 0.9963, Val Acc: 0.8678, Val AUC: 0.9071, Val F1: 0.8675, Val Recall: 0.8678, Val Loss: 1.0478, Early Stop: 17\n",
      "Epoch 60/500, Train Acc: 0.9966, Val Acc: 0.8755, Val AUC: 0.9186, Val F1: 0.8723, Val Recall: 0.8755, Val Loss: 1.0055, Early Stop: 16\n",
      "Epoch 61/500, Train Acc: 0.9971, Val Acc: 0.8740, Val AUC: 0.9168, Val F1: 0.8716, Val Recall: 0.8740, Val Loss: 1.1200, Early Stop: 15\n",
      "Epoch 62/500, Train Acc: 0.9967, Val Acc: 0.8730, Val AUC: 0.9177, Val F1: 0.8717, Val Recall: 0.8730, Val Loss: 1.0244, Early Stop: 14\n",
      "Decay learning rate to lr: 9.655172413793103e-05.\n",
      "Epoch 63/500, Train Acc: 0.9961, Val Acc: 0.8527, Val AUC: 0.9108, Val F1: 0.8444, Val Recall: 0.8527, Val Loss: 1.2692, Early Stop: 13\n",
      "Decay learning rate to lr: 9.310344827586206e-05.\n",
      "Epoch 64/500, Train Acc: 0.9968, Val Acc: 0.8691, Val AUC: 0.9194, Val F1: 0.8651, Val Recall: 0.8691, Val Loss: 1.0849, Early Stop: 12\n",
      "Decay learning rate to lr: 8.965517241379309e-05.\n",
      "Epoch 65/500, Train Acc: 0.9974, Val Acc: 0.8719, Val AUC: 0.9259, Val F1: 0.8714, Val Recall: 0.8719, Val Loss: 1.0055, Early Stop: 11\n",
      "Decay learning rate to lr: 8.620689655172413e-05.\n",
      "Epoch 66/500, Train Acc: 0.9968, Val Acc: 0.8753, Val AUC: 0.9217, Val F1: 0.8740, Val Recall: 0.8753, Val Loss: 1.0145, Early Stop: 10\n",
      "Decay learning rate to lr: 8.275862068965516e-05.\n",
      "Epoch 67/500, Train Acc: 0.9969, Val Acc: 0.8842, Val AUC: 0.9224, Val F1: 0.8826, Val Recall: 0.8842, Val Loss: 1.0028, Early Stop: 30\n",
      "Epoch 68/500, Train Acc: 0.9969, Val Acc: 0.8755, Val AUC: 0.9195, Val F1: 0.8739, Val Recall: 0.8755, Val Loss: 1.0895, Early Stop: 29\n",
      "Epoch 69/500, Train Acc: 0.9966, Val Acc: 0.8740, Val AUC: 0.9177, Val F1: 0.8738, Val Recall: 0.8740, Val Loss: 1.0430, Early Stop: 28\n",
      "Epoch 70/500, Train Acc: 0.9974, Val Acc: 0.8655, Val AUC: 0.9049, Val F1: 0.8639, Val Recall: 0.8655, Val Loss: 1.2164, Early Stop: 27\n",
      "Epoch 71/500, Train Acc: 0.9967, Val Acc: 0.8712, Val AUC: 0.9126, Val F1: 0.8671, Val Recall: 0.8712, Val Loss: 1.1540, Early Stop: 26\n",
      "Epoch 72/500, Train Acc: 0.9974, Val Acc: 0.8691, Val AUC: 0.9093, Val F1: 0.8655, Val Recall: 0.8691, Val Loss: 1.2684, Early Stop: 25\n",
      "Epoch 73/500, Train Acc: 0.9959, Val Acc: 0.8648, Val AUC: 0.9049, Val F1: 0.8642, Val Recall: 0.8648, Val Loss: 1.2433, Early Stop: 24\n",
      "Epoch 74/500, Train Acc: 0.9970, Val Acc: 0.8673, Val AUC: 0.9044, Val F1: 0.8652, Val Recall: 0.8673, Val Loss: 1.1858, Early Stop: 23\n",
      "Epoch 75/500, Train Acc: 0.9970, Val Acc: 0.8558, Val AUC: 0.9027, Val F1: 0.8488, Val Recall: 0.8558, Val Loss: 1.3257, Early Stop: 22\n",
      "Epoch 76/500, Train Acc: 0.9975, Val Acc: 0.8696, Val AUC: 0.9191, Val F1: 0.8660, Val Recall: 0.8696, Val Loss: 1.1037, Early Stop: 21\n",
      "Epoch 77/500, Train Acc: 0.9972, Val Acc: 0.8668, Val AUC: 0.9200, Val F1: 0.8625, Val Recall: 0.8668, Val Loss: 1.1276, Early Stop: 20\n",
      "Epoch 78/500, Train Acc: 0.9974, Val Acc: 0.8671, Val AUC: 0.9130, Val F1: 0.8647, Val Recall: 0.8671, Val Loss: 1.1277, Early Stop: 19\n",
      "Epoch 79/500, Train Acc: 0.9969, Val Acc: 0.8653, Val AUC: 0.9040, Val F1: 0.8629, Val Recall: 0.8653, Val Loss: 1.2994, Early Stop: 18\n",
      "Epoch 80/500, Train Acc: 0.9971, Val Acc: 0.8637, Val AUC: 0.9096, Val F1: 0.8582, Val Recall: 0.8637, Val Loss: 1.4275, Early Stop: 17\n",
      "Epoch 81/500, Train Acc: 0.9966, Val Acc: 0.8665, Val AUC: 0.9189, Val F1: 0.8622, Val Recall: 0.8665, Val Loss: 1.3327, Early Stop: 16\n",
      "Epoch 82/500, Train Acc: 0.9970, Val Acc: 0.8676, Val AUC: 0.9144, Val F1: 0.8627, Val Recall: 0.8676, Val Loss: 1.3122, Early Stop: 15\n",
      "Epoch 83/500, Train Acc: 0.9969, Val Acc: 0.8653, Val AUC: 0.9093, Val F1: 0.8623, Val Recall: 0.8653, Val Loss: 1.3205, Early Stop: 14\n",
      "Decay learning rate to lr: 7.990487514863257e-05.\n",
      "Epoch 84/500, Train Acc: 0.9964, Val Acc: 0.8640, Val AUC: 0.9094, Val F1: 0.8612, Val Recall: 0.8640, Val Loss: 1.2433, Early Stop: 13\n",
      "Decay learning rate to lr: 7.705112960760998e-05.\n",
      "Epoch 85/500, Train Acc: 0.9975, Val Acc: 0.8665, Val AUC: 0.9090, Val F1: 0.8638, Val Recall: 0.8665, Val Loss: 1.2844, Early Stop: 12\n",
      "Decay learning rate to lr: 7.419738406658739e-05.\n",
      "Epoch 86/500, Train Acc: 0.9976, Val Acc: 0.8727, Val AUC: 0.9090, Val F1: 0.8710, Val Recall: 0.8727, Val Loss: 1.2679, Early Stop: 11\n",
      "Decay learning rate to lr: 7.13436385255648e-05.\n",
      "Epoch 87/500, Train Acc: 0.9971, Val Acc: 0.8701, Val AUC: 0.9122, Val F1: 0.8670, Val Recall: 0.8701, Val Loss: 1.3103, Early Stop: 10\n",
      "Decay learning rate to lr: 6.848989298454222e-05.\n",
      "Epoch 88/500, Train Acc: 0.9971, Val Acc: 0.8719, Val AUC: 0.9173, Val F1: 0.8679, Val Recall: 0.8719, Val Loss: 1.2621, Early Stop: 9\n",
      "Decay learning rate to lr: 6.563614744351963e-05.\n",
      "Epoch 89/500, Train Acc: 0.9976, Val Acc: 0.8696, Val AUC: 0.9087, Val F1: 0.8695, Val Recall: 0.8696, Val Loss: 1.2432, Early Stop: 8\n",
      "Decay learning rate to lr: 6.278240190249704e-05.\n",
      "Epoch 90/500, Train Acc: 0.9975, Val Acc: 0.8627, Val AUC: 0.9148, Val F1: 0.8557, Val Recall: 0.8627, Val Loss: 1.4087, Early Stop: 7\n",
      "Decay learning rate to lr: 5.992865636147444e-05.\n",
      "Epoch 91/500, Train Acc: 0.9957, Val Acc: 0.8683, Val AUC: 0.9179, Val F1: 0.8662, Val Recall: 0.8683, Val Loss: 1.2567, Early Stop: 6\n",
      "Decay learning rate to lr: 5.7074910820451846e-05.\n",
      "Epoch 92/500, Train Acc: 0.9978, Val Acc: 0.8617, Val AUC: 0.9101, Val F1: 0.8592, Val Recall: 0.8617, Val Loss: 1.3908, Early Stop: 5\n",
      "Decay learning rate to lr: 5.422116527942926e-05.\n",
      "Epoch 93/500, Train Acc: 0.9971, Val Acc: 0.8699, Val AUC: 0.9141, Val F1: 0.8685, Val Recall: 0.8699, Val Loss: 1.2313, Early Stop: 4\n",
      "Decay learning rate to lr: 5.136741973840667e-05.\n",
      "Epoch 94/500, Train Acc: 0.9974, Val Acc: 0.8704, Val AUC: 0.9201, Val F1: 0.8666, Val Recall: 0.8704, Val Loss: 1.2101, Early Stop: 3\n",
      "Decay learning rate to lr: 4.851367419738407e-05.\n",
      "Epoch 95/500, Train Acc: 0.9977, Val Acc: 0.8768, Val AUC: 0.9170, Val F1: 0.8730, Val Recall: 0.8768, Val Loss: 1.2483, Early Stop: 2\n",
      "Decay learning rate to lr: 4.565992865636148e-05.\n",
      "Epoch 96/500, Train Acc: 0.9984, Val Acc: 0.8735, Val AUC: 0.9163, Val F1: 0.8708, Val Recall: 0.8735, Val Loss: 1.3187, Early Stop: 1\n",
      "Decay learning rate to lr: 4.280618311533889e-05.\n"
     ]
    }
   ],
   "source": [
    "# Training and validation\n",
    "num_epochs = 500\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "val_auc_history = []\n",
    "val_f1_history = []\n",
    "val_r_history = []\n",
    "\n",
    "min_loss = float('inf') # 初始min_loss无穷大\n",
    "best_acc = 0.0\n",
    "best_auc = 0.0\n",
    "patience = 30 # patience原来设成80，设为30当连续20个epoch不再下降时，改变学习率\n",
    "early_stop = patience\n",
    "change_rate = 15 # 多少个epoch不发生提升时，改变学习率\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    flair_model.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device) # 图像与标签\n",
    "        optimizer.zero_grad()\n",
    "        outputs = flair_model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels) # 交叉熵损失函数集成了softmax，直接将模型的输出当成参数传入即可，不需要额外的softmax操作（否则报错）\n",
    "        # print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # _, predicted = torch.max(outputs, 1)\n",
    "        predicted = torch.argmax(outputs, 1) # argmax获得标签，用于计算acc等指标\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    # 调整学习率, 一个epoch结束后调整学习率\n",
    "    # print('current epoch lr:', optimizer.param_groups[0]['lr'])\n",
    "    # dynamic_lr.step()\n",
    "    lr = optimizer.param_groups[0]['lr'] # 当前epoch的学习率\n",
    "    # 当early stop连续20次指标不再上升时，改变学习率\n",
    "    if early_stop < (patience - change_rate):\n",
    "        lr -= lr / (change_rate + early_stop)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        print ('Decay learning rate to lr: {}.'.format(lr))\n",
    "    \n",
    "    train_acc = train_correct / train_total\n",
    "    train_acc_history.append(train_acc)\n",
    "\n",
    "    \n",
    "    # Validation\n",
    "    flair_model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_outputs_list = []\n",
    "    val_labels_list = []\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = flair_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # _, predicted = torch.max(outputs, 1)\n",
    "            predicted = torch.argmax(outputs, 1)\n",
    "    \n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_outputs_list.append(outputs.cpu().numpy())\n",
    "            val_labels_list.append(labels.cpu().numpy())\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_acc_history.append(val_acc)\n",
    "\n",
    "        val_outputs = np.concatenate(val_outputs_list, axis=0)\n",
    "        val_labels = np.concatenate(val_labels_list, axis=0)\n",
    "\n",
    "        val_fpr, val_tpr, _ = roc_curve(val_labels, val_outputs[:, 1], pos_label=1) # 计算auc，val_outputs[:, 1]表示对正类别的预测概率\n",
    "        val_auc = auc(val_fpr, val_tpr)\n",
    "        val_auc_history.append(val_auc)\n",
    "\n",
    "        val_f1 = f1_score(val_labels, np.argmax(val_outputs, axis=1),average='weighted')\n",
    "        val_f1_history.append(val_f1)\n",
    "\n",
    "        val_r = recall_score(val_labels, np.argmax(val_outputs, axis=1),average='weighted')\n",
    "        val_r_history.append(val_r)\n",
    "\n",
    "        # Calculate average validation loss\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        # 得到验证集的平均损失\n",
    "        # 设置早停点\n",
    "        # if min_loss > avg_val_loss:\n",
    "        if best_acc < val_acc: # 以auc值最大存储最佳模型\n",
    "            # min_loss = avg_val_loss\n",
    "            best_acc = val_acc\n",
    "            early_stop = patience\n",
    "            model_name = 'flair_model_c3.pth' # 损失值最小的时候设置成最佳模型\n",
    "            torch.save(flair_model.state_dict(), model_name)\n",
    "        else: # 当前的平均损失比之前epoch的要大\n",
    "            early_stop -= 1\n",
    "        \n",
    "        # 当early_stop为0时，结束epoch训练\n",
    "        if early_stop == 0:\n",
    "            break\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}, Val F1: {val_f1:.4f}, Val Recall: {val_r:.4f}, Val Loss: {avg_val_loss:.4f}, Early Stop: {early_stop:.0f}\")\n",
    "        \n",
    "\n",
    "plot_train_curve('flair', train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68e1612d-705e-4ad9-98c9-05117f40a86c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(model.state_dict(), \"swin_model_brat_cls_2024_4_21.pth\") # 存储模型\n",
    "flair_model.load_state_dict(torch.load(\"flair_model_c3.pth\")) # 加载训练阶段存储的最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c859d144-6ad9-4a0e-b2aa-c3c572f2d56b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_train_curve('flair', train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "339f1fdc-f721-4f88-9f79-3deb519be738",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_train_curve('flair', train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33d92fc8-aba1-49a6-a606-7b58da2659cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, f1_score, recall_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "170edb83-063b-48a9-aaa2-5691cce34362",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8395, AUC: 0.8988, F1 Score: 0.8354, Recall: 0.8395\n"
     ]
    }
   ],
   "source": [
    "# Create a data loader for the images\n",
    "import torch.nn.functional as F\n",
    "data_dir = \"/root/autodl-tmp/project/MedSAM-0.1/data/MULTI_TUMOR_split/test\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "image_data = datasets.ImageFolder(data_dir, transform=transform)\n",
    "data_loader = DataLoader(image_data, batch_size=1, shuffle=False)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = flair_model(images)\n",
    "        probabilities = F.softmax(outputs, dim=1)  # 使用softmax函数进行概率化处理\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.append(labels.item())\n",
    "        y_pred.append(predicted.item())\n",
    "        y_scores.append(probabilities.cpu().numpy())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "y_scores = np.concatenate(y_scores, axis=0)\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "auc_score = roc_auc_score(y_true, y_scores[:, 1], multi_class='ovo')\n",
    "f1 = f1_score(y_true, y_pred,average='weighted')\n",
    "recall = recall_score(y_true, y_pred,average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}, AUC: {auc_score:.4f}, F1 Score: {f1:.4f}, Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a380bc6-472c-4550-96e1-d5c9959b143b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.66      1029\n",
      "           1       0.87      0.92      0.89      2978\n",
      "\n",
      "    accuracy                           0.84      4007\n",
      "   macro avg       0.80      0.77      0.78      4007\n",
      "weighted avg       0.83      0.84      0.84      4007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19e357c0-7bb9-43c0-b99e-a960a71ced5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Define class labels\n",
    "labels = ['LGG','NGG']  # 用您的实际类别标签替换...\n",
    "\n",
    "# Plot confusion matrix\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "plt.figure()\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\".0f\", cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d9406f-1473-480b-9e14-8ada00383ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825ab579-b756-4180-ac69-0154b744b05d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccb9c6e-2560-4064-9f95-8499f956d6f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828585b1-8648-46c1-b4a4-279a5c8e3015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c18544-68c2-4fc6-949f-c501b69811c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc0c883-f06b-40fb-9320-2d4bf1832b9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 将模型训练和验证的方式改成交叉验证，解决数据不平衡时测试引入的误差\n",
    "# 改成独立测试后，不运行以下代码\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Set loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.BCELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "batch_size = 64\n",
    "# Training and validation\n",
    "num_epochs = 500 # 预训练的基础上，可减少训练的epoch数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb182a64-9d83-4b78-b16b-05d5478594c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使用交叉验证，不区分训练集和测试集\n",
    "dataset = ConcatDataset([train_data, test_data])\n",
    "# dataset, _ = random_split(dataset, [2000, len(dataset)-2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bdf001-9b7e-4c17-ab8e-ade4913f6617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载dataset中的每一项，统计其中的0和1数量，构造出targets数组\n",
    "targets = []\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=64)\n",
    "for images, labels in loader:\n",
    "    targets.append(labels.item())\n",
    "    # print(labels)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014edf57-91c9-4962-a80a-9dc174f74549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(targets)\n",
    "# targets.count(0)\n",
    "# targets.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d493fb0-d611-48f0-a0ec-f572b93142d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb4e5a1-4069-44ff-a693-914b1ee5bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#跑t1 t1ce flair的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db978353-48e7-4042-b5b5-2dcba636c865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 在次定义训练曲线绘制函数与混淆矩阵绘制函数\n",
    "def plot_train_curve(kfold ,train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr):\n",
    "    # 传入的参数train acc; val acc; val auc; val f1; val r; val fpr; val tpr\n",
    "    plt.figure()\n",
    "    plt.plot(train_acc_history, label=\"Train Acc\")\n",
    "    plt.plot(val_acc_history, label=\"Val Acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'Acc_curve_of_' + str(kfold) + '_fold_c3.png') # 存储acc的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_auc_history, label=\"Val AUC\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'Auc_curve_of_' + str(kfold) + '_fold_c3.png') # 存储val auc的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_f1_history, label=\"Val F1\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'F1_curve_of_' + str(kfold) + '_fold_c3.png') # 存储val f1的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_r_history, label=\"Val Recall\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Recall\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'Recall_curve_of_' + str(kfold) + '_fold_c3.png') # 存储val recall的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(val_fpr, val_tpr, label=f'ROC curve (area = {val_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('./train_curve_images/' + 'ROC_curve_of_' + str(kfold) + '_fold_c3.png') # 存储ROC\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_martix(kfold, y_true, y_pred): # 传入的是训练预测得到的标签与真实的标签\n",
    "    # Define class labels\n",
    "    labels = ['HGG','LGG']  # 用您的实际类别标签替换... LGG表示低级别胶质瘤，HGG表示高级别胶质瘤\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure()\n",
    "    sns.heatmap(conf_mat, annot=True, fmt=\".0f\", cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted labels\")\n",
    "    plt.ylabel(\"True labels\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig('./val_confusion_martix_figs/' + 'Confusion_martix_of_' + str(kfold) + '_fold_c3.png')\n",
    "    # plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d83098e-970f-4a64-b14c-ebc6ddbb74a7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_acc_list = []\n",
    "final_auc_list = []\n",
    "final_f1_list = []\n",
    "final_recall_list = []\n",
    "# 新建一个excel表格。存储每折运行计算得到得指标\n",
    "f = open('result_c3.csv', 'a', encoding='utf-8', newline='')\n",
    "wr = csv.writer(f)\n",
    "wr.writerow(['k-fold', 'Val Acc', 'Val AUC', 'Val F1', 'avg_fold_recall']) # csv的标题\n",
    "k = 5 # 改成3折，增大验证的数据集\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=2024)\n",
    "# for fold in range(k):\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(range(len(dataset)), targets)):\n",
    "    print(f'Fold {fold + 1}/{k}')\n",
    "    # train = [targets[i] for i in train_indices]\n",
    "    # val = [targets[i] for i in val_indices]\n",
    "    # print(type(train))\n",
    "    # print(train.count(0))\n",
    "    # print(train.count(1))\n",
    "    # print('----')\n",
    "    # print(val.count(0))\n",
    "    # print(val.count(1))\n",
    "\n",
    "    # print(fold) # 显示当前折的索引\n",
    "    \n",
    "    # 每一折分别记录训练时的指标变化，用于绘制训练曲线\n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "    val_auc_history = []\n",
    "    val_f1_history = []\n",
    "    val_r_history = []\n",
    "    # print(train_indices)\n",
    "    # print('train length', len(train_indices))\n",
    "    # print(val_indices)\n",
    "    # print('val length', len(val_indices))\n",
    "    # 获得训练和验证的索引之后\n",
    "    # print(val_indices)\n",
    "    # print(len(val_indices))\n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    val_dataset = Subset(dataset, val_indices)\n",
    "    # avg_fold_acc = 0\n",
    "    # avg_fold_auc = 0\n",
    "    # avg_fold_f1 = 0\n",
    "    # avg_fold_recall = 0\n",
    "    # print(f\"Fold {fold + 1}/{k}, Val Acc: {avg_fold_acc:.4f}, Val AUC: {avg_fold_auc:.4f}, Val F1: {avg_fold_f1:.4f}, avg_fold_recall: {avg_fold_recall:.4f}\")\n",
    "\n",
    "    # print(len(train_dataset), len(val_dataset))\n",
    "\n",
    "    # print(f'Fold {fold + 1}/{k}')\n",
    "    # train_sampler = SubsetRandomSampler(train_indices)\n",
    "    # val_sampler = SubsetRandomSampler(val_indices)\n",
    "    # dataset = dataset[:10]\n",
    "    \n",
    "    # kfold_model = model # 每折的模型要重置\n",
    "    # 模型重置的时候需要使用深拷贝，不能直接使用赋值语句\n",
    "    kfold_model = copy.deepcopy(model)\n",
    "    kfold_model.to(device)\n",
    "    params_to_update_kfold_model = [] # 对拷贝后的模型，也只更新最后几层\n",
    "    for name, param in kfold_model.named_parameters():\n",
    "        # if name not in ['norm.weight', 'norm.bias', 'head.weight', 'head.bias']: # 只训练最后几层\n",
    "        #     param.requires_grad = False \n",
    "        # else:\n",
    "        #     param.requires_grad = True # 手动设置，不然不会自动赋值\n",
    "        #     params_to_update_kfold_model.append(param)\n",
    "        \n",
    "        # 冻结倒数前30层\n",
    "        if name.find(\"layers.3\") == -1: # 当前层不含layer.3不更新权重\n",
    "            param.requires_grad = False\n",
    "        if name.find(\"layers.3\") == -1 and name not in ['norm.weight', 'norm.bias', 'head.weight', 'head.bias']: #  当前层不含layer.3且name不等于列表中的\n",
    "            param.requires_grad = False\n",
    "        else: # 后30层网络需要训练\n",
    "            param.requires_grad = True # 手动设置，不然不会自动赋值\n",
    "            params_to_update_kfold_model.append(param)\n",
    "        \n",
    "        # # 冻结倒数前4层\n",
    "        # if name not in ['norm.weight', 'norm.bias', 'head.weight', 'head.bias', 'layers.3.blocks.1.mlp.fc1.weight', 'layers.3.blocks.1.mlp.fc1.bias', 'layers.3.blocks.1.mlp.fc2.weight', 'layers.3.blocks.1.mlp.fc2.bias']: # 只训练最后几层\n",
    "        #     param.requires_grad = False \n",
    "        # else:\n",
    "        #     param.requires_grad = True # 手动设置，不然不会自动赋值\n",
    "        #     params_to_update_kfold_model.append(param)\n",
    "    # print(len(params_to_update_kfold_model))\n",
    "    # 冻结某些层后，修改optimizer，只更新未冻结的层\n",
    "    optimizer = optim.Adam(params_to_update_kfold_model, lr=1e-4)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=64)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=64)    \n",
    "    \n",
    "    epochs_acc_list = []\n",
    "    epochs_auc_list = []\n",
    "    epochs_f1_list = []\n",
    "    epochs_recall_list = []\n",
    "    best_acc = 0.\n",
    "    best_auc = 0.\n",
    "    best_f1 = 0.\n",
    "    best_recall = 0.\n",
    "    \n",
    "    # 早停点\n",
    "    min_loss = float('inf') # 初始min_loss无穷大\n",
    "    patience = 20\n",
    "    early_stop = patience\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        kfold_model.train()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device) # 图像与标签\n",
    "            # print(labels)\n",
    "            # break\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # outputs = model(images)\n",
    "            outputs = kfold_model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels) # 交叉熵损失函数集成了softmax，直接将模型的输出当成参数传入即可，不需要额外的softmax操作（否则报错）\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # _, predicted = torch.max(outputs, 1)\n",
    "            predicted = torch.argmax(outputs, 1) # argmax获得标签，用于计算acc等指标\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_acc = train_correct / train_total\n",
    "        train_acc_history.append(train_acc)\n",
    "\n",
    "\n",
    "            # Validation\n",
    "        kfold_model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_outputs_list = []\n",
    "        val_labels_list = []\n",
    "        y_pred_list = [] # 存储预测的标签\n",
    "        val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                # outputs = model(images)\n",
    "                outputs = kfold_model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # _, predicted = torch.max(outputs, 1)\n",
    "                predicted = torch.argmax(outputs, 1)\n",
    "\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_outputs_list.append(outputs.cpu().numpy())\n",
    "                y_pred_list.append(predicted.cpu().numpy())\n",
    "                val_labels_list.append(labels.cpu().numpy())\n",
    "\n",
    "            val_acc = val_correct / val_total\n",
    "            val_acc_history.append(val_acc)\n",
    "\n",
    "            val_outputs = np.concatenate(val_outputs_list, axis=0)\n",
    "            y_pred = np.concatenate(y_pred_list, axis=0)\n",
    "            val_labels = np.concatenate(val_labels_list, axis=0)\n",
    "            # y_true = np.array(y_true)\n",
    "            # y_pred = np.array(y_pred)\n",
    "            # print(predicted)\n",
    "            # print(y_pred)\n",
    "            # print(val_labels)\n",
    "            # break\n",
    "            \n",
    "\n",
    "            val_fpr, val_tpr, _ = roc_curve(val_labels, val_outputs[:, 1], pos_label=1) # 计算auc，val_outputs[:, 1]表示对正类别的预测概率\n",
    "            val_auc = auc(val_fpr, val_tpr)\n",
    "            val_auc_history.append(val_auc)\n",
    "\n",
    "            val_f1 = f1_score(val_labels, np.argmax(val_outputs, axis=1),average='weighted')\n",
    "            val_f1_history.append(val_f1)\n",
    "\n",
    "            val_r = recall_score(val_labels, np.argmax(val_outputs, axis=1),average='weighted')\n",
    "            val_r_history.append(val_r)\n",
    "\n",
    "            # Calculate average validation loss\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            # 得到验证集的平均损失\n",
    "            # 设置早停点\n",
    "            if min_loss > avg_val_loss:\n",
    "                min_loss = avg_val_loss\n",
    "                early_stop = patience\n",
    "                \n",
    "                # 验证集损失小的时候指标的值设为最佳\n",
    "                best_acc = val_acc\n",
    "                best_auc = val_auc\n",
    "                best_f1 = val_f1\n",
    "                best_recall = val_r\n",
    "                model_name = 'kfold_' + str(fold+1) + '_model_c3.pth'\n",
    "                torch.save(kfold_model.state_dict(), model_name)\n",
    "                # 在存储最佳模型的同时，利用最佳模型的结果，绘制该折的混淆矩阵\n",
    "                plot_confusion_martix(fold + 1, val_labels, y_pred)\n",
    "            else: # 当前的平均损失比之前epoch的要大\n",
    "                early_stop -= 1\n",
    "\n",
    "            # 当early_stop为0时，结束epoch训练\n",
    "            if early_stop == 0:\n",
    "                break\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}, Val F1: {val_f1:.4f}, Val Recall: {val_r:.4f}, Val Loss: {avg_val_loss:.4f}, Early Stop: {early_stop:.0f}\")\n",
    "            epochs_acc_list.append(val_acc)\n",
    "            epochs_auc_list.append(val_auc)\n",
    "            epochs_f1_list.append(val_f1)\n",
    "            epochs_recall_list.append(val_r)\n",
    "            # 每个epoch验证完成之后，存储验证性能最佳的\n",
    "            # 依据recall的值进行选择，选取此时的指标最为最佳，并存储此时的模型\n",
    "            # if val_auc > best_auc:\n",
    "            #     best_acc = val_acc\n",
    "            #     best_auc = val_auc\n",
    "            #     best_f1 = val_f1\n",
    "            #     best_recall = val_r\n",
    "            #     model_name = 'kfold_' + str(fold+1) + '_model.pth'\n",
    "            #     torch.save(kfold_model.state_dict(), model_name)\n",
    "            #     # 在存储最佳模型的同时，利用最佳模型的结果，绘制该折的混淆矩阵\n",
    "            #     plot_confusion_martix(fold + 1, val_labels, y_pred)\n",
    "            \n",
    "    # 记录验证集的各项指标作为对模型评价的结果\n",
    "    # 不同折训练100个epoch后，计算得到验证的各指标的均值，每一折验证的性能选指标最佳的\n",
    "    # avg_fold_acc = np.mean(epochs_acc_list)\n",
    "    # avg_fold_auc = np.mean(epochs_auc_list)\n",
    "    # avg_fold_f1 = np.mean(epochs_f1_list)\n",
    "    # avg_fold_recall = np.mean(epochs_recall_list)\n",
    "    \n",
    "    # 每一折获得的平均值存储起来\n",
    "    final_acc_list.append(best_acc)\n",
    "    final_auc_list.append(best_auc)\n",
    "    final_f1_list.append(best_f1)\n",
    "    final_recall_list.append(best_recall)\n",
    "    # avg_fold_acc = 0\n",
    "    # avg_fold_auc = 0\n",
    "    # avg_fold_f1 = 0\n",
    "    # val_r = 0\n",
    "    wr.writerow([fold + 1, best_acc, best_auc, best_f1, best_recall])\n",
    "    print(f\"Fold {fold + 1}/{k}, Val Acc: {best_acc:.4f}, Val AUC: {best_auc:.4f}, Val F1: {best_f1:.4f}, avg_fold_recall: {best_recall:.4f}\")\n",
    "    # 绘制训练曲线\n",
    "    plot_train_curve(fold + 1, train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7243202-81c1-4fed-91a2-4972abcfb29f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc = np.mean(final_acc_list)\n",
    "auc_score = np.mean(final_auc_list)\n",
    "f1 = np.mean(final_f1_list)\n",
    "recall = np.mean(final_recall_list)\n",
    "print(f\"Accuracy: {acc:.4f}, AUC: {auc_score:.4f}, F1 Score: {f1:.4f}, Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aafdc73-63a9-4c6c-988d-4f3289de874c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ead2e5-4116-4866-91ea-d52a6ca03d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 跑单T1输入的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5222d5c-23b9-4992-a16c-8fba95456694",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "data_dir = \"/root/autodl-tmp/project/MedSAM-0.1/data/classfication_t1_data\" # 数据存储的根目录\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=transform)\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, \"test\"), transform=transform)\n",
    "\n",
    "# 使用交叉验证，不区分训练集和测试集\n",
    "dataset = ConcatDataset([train_data, test_data])\n",
    "# 加载dataset中的每一项，统计其中的0和1数量，构造出targets数组\n",
    "targets = []\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=64)\n",
    "for images, labels in loader:\n",
    "    targets.append(labels.item())\n",
    "\n",
    "# 在次定义训练曲线绘制函数与混淆矩阵绘制函数\n",
    "def plot_train_curve(kfold ,train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr):\n",
    "    # 传入的参数train acc; val acc; val auc; val f1; val r; val fpr; val tpr\n",
    "    plt.figure()\n",
    "    plt.plot(train_acc_history, label=\"Train Acc\")\n",
    "    plt.plot(val_acc_history, label=\"Val Acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'Acc_curve_of_' + str(kfold) + '_fold_T1.png') # 存储acc的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_auc_history, label=\"Val AUC\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'Auc_curve_of_' + str(kfold) + '_fold_T1.png') # 存储val auc的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_f1_history, label=\"Val F1\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'F1_curve_of_' + str(kfold) + '_fold_T1.png') # 存储val f1的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_r_history, label=\"Val Recall\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Recall\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'Recall_curve_of_' + str(kfold) + '_fold_T1.png') # 存储val recall的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(val_fpr, val_tpr, label=f'ROC curve (area = {val_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('./train_curve_images/' + 'ROC_curve_of_' + str(kfold) + '_fold_T1.png') # 存储ROC\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_martix(kfold, y_true, y_pred): # 传入的是训练预测得到的标签与真实的标签\n",
    "    # Define class labels\n",
    "    labels = ['HGG','LGG']  # 用您的实际类别标签替换... LGG表示低级别胶质瘤，HGG表示高级别胶质瘤\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure()\n",
    "    sns.heatmap(conf_mat, annot=True, fmt=\".0f\", cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted labels\")\n",
    "    plt.ylabel(\"True labels\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig('./val_confusion_martix_figs/' + 'Confusion_martix_of_' + str(kfold) + '_fold_T1.png')\n",
    "    # plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c067ed8-3b9b-4dd2-8368-fd0db20248ee",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_acc_list = []\n",
    "final_auc_list = []\n",
    "final_f1_list = []\n",
    "final_recall_list = []\n",
    "# 新建一个excel表格。存储每折运行计算得到得指标\n",
    "f = open('result_T1.csv', 'a', encoding='utf-8', newline='')\n",
    "wr = csv.writer(f)\n",
    "wr.writerow(['k-fold', 'Val Acc', 'Val AUC', 'Val F1', 'avg_fold_recall']) # csv的标题\n",
    "k = 5 # 改成3折，增大验证的数据集\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=2024)\n",
    "# for fold in range(k):\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(range(len(dataset)), targets)):\n",
    "    print(f'Fold {fold + 1}/{k}')\n",
    "    \n",
    "    # 每一折分别记录训练时的指标变化，用于绘制训练曲线\n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "    val_auc_history = []\n",
    "    val_f1_history = []\n",
    "    val_r_history = []\n",
    "\n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    val_dataset = Subset(dataset, val_indices)\n",
    "    \n",
    "    # kfold_model = model # 每折的模型要重置\n",
    "    # 模型重置的时候需要使用深拷贝，不能直接使用赋值语句\n",
    "    kfold_model = copy.deepcopy(model)\n",
    "    kfold_model.to(device)\n",
    "    params_to_update_kfold_model = [] # 对拷贝后的模型，也只更新最后几层\n",
    "    for name, param in kfold_model.named_parameters():\n",
    "        # if name not in ['norm.weight', 'norm.bias', 'head.weight', 'head.bias']: # 只训练最后几层\n",
    "        #     param.requires_grad = False \n",
    "        # else:\n",
    "        #     param.requires_grad = True # 手动设置，不然不会自动赋值\n",
    "        #     params_to_update_kfold_model.append(param)\n",
    "\n",
    "        # 冻结倒数前30层\n",
    "        if name.find(\"layers.3\") == -1: # 当前层不含layer.3不更新权重\n",
    "            param.requires_grad = False\n",
    "        if name.find(\"layers.3\") == -1 and name not in ['norm.weight', 'norm.bias', 'head.weight', 'head.bias']: #  当前层不含layer.3且name不等于列表中的\n",
    "            param.requires_grad = False\n",
    "        else: # 后30层网络需要训练\n",
    "            param.requires_grad = True # 手动设置，不然不会自动赋值\n",
    "            params_to_update_kfold_model.append(param)\n",
    "\n",
    "        # print(name)\n",
    "    \n",
    "    # 冻结某些层后，修改optimizer，只更新未冻结的层\n",
    "    optimizer = optim.Adam(params_to_update_kfold_model, lr=1e-4)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=64)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=64)    \n",
    "    \n",
    "    epochs_acc_list = []\n",
    "    epochs_auc_list = []\n",
    "    epochs_f1_list = []\n",
    "    epochs_recall_list = []\n",
    "    best_acc = 0.\n",
    "    best_auc = 0.\n",
    "    best_f1 = 0.\n",
    "    best_recall = 0.\n",
    "\n",
    "    # 早停点\n",
    "    min_loss = float('inf') # 初始min_loss无穷大\n",
    "    patience = 20\n",
    "    early_stop = patience\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        kfold_model.train()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device) # 图像与标签\n",
    "            # print(labels)\n",
    "            # break\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # outputs = model(images)\n",
    "            outputs = kfold_model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels) # 交叉熵损失函数集成了softmax，直接将模型的输出当成参数传入即可，不需要额外的softmax操作（否则报错）\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # _, predicted = torch.max(outputs, 1)\n",
    "            predicted = torch.argmax(outputs, 1) # argmax获得标签，用于计算acc等指标\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_acc = train_correct / train_total\n",
    "        train_acc_history.append(train_acc)\n",
    "\n",
    "\n",
    "            # Validation\n",
    "        kfold_model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_outputs_list = []\n",
    "        val_labels_list = []\n",
    "        y_pred_list = [] # 存储预测的标签\n",
    "        val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                # outputs = model(images)\n",
    "                outputs = kfold_model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # _, predicted = torch.max(outputs, 1)\n",
    "                predicted = torch.argmax(outputs, 1)\n",
    "\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_outputs_list.append(outputs.cpu().numpy())\n",
    "                y_pred_list.append(predicted.cpu().numpy())\n",
    "                val_labels_list.append(labels.cpu().numpy())\n",
    "\n",
    "            val_acc = val_correct / val_total\n",
    "            val_acc_history.append(val_acc)\n",
    "\n",
    "            val_outputs = np.concatenate(val_outputs_list, axis=0)\n",
    "            y_pred = np.concatenate(y_pred_list, axis=0)\n",
    "            val_labels = np.concatenate(val_labels_list, axis=0)\n",
    "            # y_true = np.array(y_true)\n",
    "            # y_pred = np.array(y_pred)\n",
    "            # print(predicted)\n",
    "            # print(y_pred)\n",
    "            # print(val_labels)\n",
    "            # break\n",
    "            \n",
    "\n",
    "            val_fpr, val_tpr, _ = roc_curve(val_labels, val_outputs[:, 1], pos_label=1) # 计算auc，val_outputs[:, 1]表示对正类别的预测概率\n",
    "            val_auc = auc(val_fpr, val_tpr)\n",
    "            val_auc_history.append(val_auc)\n",
    "\n",
    "            val_f1 = f1_score(val_labels, np.argmax(val_outputs, axis=1),average='weighted')\n",
    "            val_f1_history.append(val_f1)\n",
    "\n",
    "            val_r = recall_score(val_labels, np.argmax(val_outputs, axis=1),average='weighted')\n",
    "            val_r_history.append(val_r)\n",
    "\n",
    "            # Calculate average validation loss\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            \n",
    "            if min_loss > avg_val_loss:\n",
    "                min_loss = avg_val_loss\n",
    "                early_stop = patience\n",
    "                \n",
    "                # 验证集损失小的时候指标的值设为最佳\n",
    "                best_acc = val_acc\n",
    "                best_auc = val_auc\n",
    "                best_f1 = val_f1\n",
    "                best_recall = val_r\n",
    "                model_name = 'kfold_' + str(fold+1) + '_model_T1.pth'\n",
    "                torch.save(kfold_model.state_dict(), model_name)\n",
    "                # 在存储最佳模型的同时，利用最佳模型的结果，绘制该折的混淆矩阵\n",
    "                plot_confusion_martix(fold + 1, val_labels, y_pred)\n",
    "            else: # 当前的平均损失比之前epoch的要大\n",
    "                early_stop -= 1\n",
    "\n",
    "            # 当early_stop为0时，结束epoch训练\n",
    "            if early_stop == 0:\n",
    "                break\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}, Val F1: {val_f1:.4f}, Val Recall: {val_r:.4f}, Val Loss: {avg_val_loss:.4f}, Early Stop: {early_stop:.0f}\")\n",
    "   \n",
    "            # print(f\"Epoch {epoch + 1}/{num_epochs}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}, Val F1: {val_f1:.4f}, Val Recall: {val_r:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "            epochs_acc_list.append(val_acc)\n",
    "            epochs_auc_list.append(val_auc)\n",
    "            epochs_f1_list.append(val_f1)\n",
    "            epochs_recall_list.append(val_r)\n",
    "            # 每个epoch验证完成之后，存储验证性能最佳的\n",
    "            # 依据recall的值进行选择，选取此时的指标最为最佳，并存储此时的模型\n",
    "            # if val_auc > best_auc:\n",
    "            #     best_acc = val_acc\n",
    "            #     best_auc = val_auc\n",
    "            #     best_f1 = val_f1\n",
    "            #     best_recall = val_r\n",
    "            #     model_name = 'kfold_' + str(fold+1) + '_model_T1.pth'\n",
    "            #     torch.save(kfold_model.state_dict(), model_name)\n",
    "            #     # 在存储最佳模型的同时，利用最佳模型的结果，绘制该折的混淆矩阵\n",
    "            #     plot_confusion_martix(fold + 1, val_labels, y_pred)\n",
    "            \n",
    "    # 记录验证集的各项指标作为对模型评价的结果\n",
    "    # 不同折训练100个epoch后，计算得到验证的各指标的均值，每一折验证的性能选指标最佳的\n",
    "    # avg_fold_acc = np.mean(epochs_acc_list)\n",
    "    # avg_fold_auc = np.mean(epochs_auc_list)\n",
    "    # avg_fold_f1 = np.mean(epochs_f1_list)\n",
    "    # avg_fold_recall = np.mean(epochs_recall_list)\n",
    "    \n",
    "    # 每一折获得的平均值存储起来\n",
    "    final_acc_list.append(best_acc)\n",
    "    final_auc_list.append(best_auc)\n",
    "    final_f1_list.append(best_f1)\n",
    "    final_recall_list.append(best_recall)\n",
    "    # avg_fold_acc = 0\n",
    "    # avg_fold_auc = 0\n",
    "    # avg_fold_f1 = 0\n",
    "    # val_r = 0\n",
    "    wr.writerow([fold + 1, best_acc, best_auc, best_f1, best_recall])\n",
    "    print(f\"Fold {fold + 1}/{k}, Val Acc: {best_acc:.4f}, Val AUC: {best_auc:.4f}, Val F1: {best_f1:.4f}, avg_fold_recall: {best_recall:.4f}\")\n",
    "    # 绘制训练曲线\n",
    "    plot_train_curve(fold + 1, train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433d472-01e1-493a-a0eb-27c273bc35c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc = np.mean(final_acc_list)\n",
    "auc_score = np.mean(final_auc_list)\n",
    "f1 = np.mean(final_f1_list)\n",
    "recall = np.mean(final_recall_list)\n",
    "print(f\"T1: Accuracy: {acc:.4f}, AUC: {auc_score:.4f}, F1 Score: {f1:.4f}, Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db42a6-25d4-4db3-9dc0-32a8f27dceb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2ccaf8-916a-4ba4-a619-4fccf01983d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单flair作为输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e6b748-4610-428e-8f71-cb6f84c1d6a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "data_dir = \"/root/autodl-tmp/project/MedSAM-0.1/data/classfication_data_copy\" # 数据存储的根目录\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=transform)\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, \"test\"), transform=transform)\n",
    "\n",
    "# 使用交叉验证，不区分训练集和测试集\n",
    "dataset = ConcatDataset([train_data, test_data])\n",
    "# 加载dataset中的每一项，统计其中的0和1数量，构造出targets数组\n",
    "targets = []\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=64)\n",
    "for images, labels in loader:\n",
    "    targets.append(labels.item())\n",
    "\n",
    "# 在次定义训练曲线绘制函数与混淆矩阵绘制函数\n",
    "def plot_train_curve(kfold ,train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr):\n",
    "    # 传入的参数train acc; val acc; val auc; val f1; val r; val fpr; val tpr\n",
    "    plt.figure()\n",
    "    plt.plot(train_acc_history, label=\"Train Acc\")\n",
    "    plt.plot(val_acc_history, label=\"Val Acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'Acc_curve_of_' + str(kfold) + '_fold_flair.png') # 存储acc的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_auc_history, label=\"Val AUC\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'Auc_curve_of_' + str(kfold) + '_fold_flair.png') # 存储val auc的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_f1_history, label=\"Val F1\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'F1_curve_of_' + str(kfold) + '_fold_flair.png') # 存储val f1的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_r_history, label=\"Val Recall\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Recall\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'Recall_curve_of_' + str(kfold) + '_fold_flair.png') # 存储val recall的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(val_fpr, val_tpr, label=f'ROC curve (area = {val_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('./train_curve_images/' + 'ROC_curve_of_' + str(kfold) + '_fold_flair.png') # 存储ROC\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_martix(kfold, y_true, y_pred): # 传入的是训练预测得到的标签与真实的标签\n",
    "    # Define class labels\n",
    "    labels = ['HGG','LGG']  # 用您的实际类别标签替换... LGG表示低级别胶质瘤，HGG表示高级别胶质瘤\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure()\n",
    "    sns.heatmap(conf_mat, annot=True, fmt=\".0f\", cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted labels\")\n",
    "    plt.ylabel(\"True labels\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig('./val_confusion_martix_figs/' + 'Confusion_martix_of_' + str(kfold) + '_fold_flair.png')\n",
    "    # plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6932ed2b-dfa3-438d-9b5e-e248d071e016",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_acc_list = []\n",
    "final_auc_list = []\n",
    "final_f1_list = []\n",
    "final_recall_list = []\n",
    "# 新建一个excel表格。存储每折运行计算得到得指标\n",
    "f = open('result_flair.csv', 'a', encoding='utf-8', newline='')\n",
    "wr = csv.writer(f)\n",
    "wr.writerow(['k-fold', 'Val Acc', 'Val AUC', 'Val F1', 'avg_fold_recall']) # csv的标题\n",
    "k = 5 # 改成3折，增大验证的数据集\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=2024)\n",
    "# for fold in range(k):\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(range(len(dataset)), targets)):\n",
    "    print(f'Fold {fold + 1}/{k}')\n",
    "    \n",
    "    # 每一折分别记录训练时的指标变化，用于绘制训练曲线\n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "    val_auc_history = []\n",
    "    val_f1_history = []\n",
    "    val_r_history = []\n",
    "\n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    val_dataset = Subset(dataset, val_indices)\n",
    "    \n",
    "    # kfold_model = model # 每折的模型要重置\n",
    "    # 模型重置的时候需要使用深拷贝，不能直接使用赋值语句\n",
    "    kfold_model = copy.deepcopy(model)\n",
    "    kfold_model.to(device)\n",
    "    params_to_update_kfold_model = [] # 对拷贝后的模型，也只更新最后几层\n",
    "    for name, param in kfold_model.named_parameters():\n",
    "        # if name not in ['norm.weight', 'norm.bias', 'head.weight', 'head.bias']: # 只训练最后几层\n",
    "        #     param.requires_grad = False \n",
    "        # else:\n",
    "        #     param.requires_grad = True # 手动设置，不然不会自动赋值\n",
    "        #     params_to_update_kfold_model.append(param)\n",
    "        \n",
    "        # 冻结倒数前30层\n",
    "        if name.find(\"layers.3\") == -1: # 当前层不含layer.3不更新权重\n",
    "            param.requires_grad = False\n",
    "        if name.find(\"layers.3\") == -1 and name not in ['norm.weight', 'norm.bias', 'head.weight', 'head.bias']: #  当前层不含layer.3且name不等于列表中的\n",
    "            param.requires_grad = False\n",
    "        else: # 后30层网络需要训练\n",
    "            param.requires_grad = True # 手动设置，不然不会自动赋值\n",
    "            params_to_update_kfold_model.append(param)\n",
    "\n",
    "        # print(name)\n",
    "    \n",
    "    # 冻结某些层后，修改optimizer，只更新未冻结的层\n",
    "    optimizer = optim.Adam(params_to_update_kfold_model, lr=1e-4)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=64)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=64)    \n",
    "    \n",
    "    epochs_acc_list = []\n",
    "    epochs_auc_list = []\n",
    "    epochs_f1_list = []\n",
    "    epochs_recall_list = []\n",
    "    best_acc = 0.\n",
    "    best_auc = 0.\n",
    "    best_f1 = 0.\n",
    "    best_recall = 0.\n",
    "   \n",
    "    # 早停点\n",
    "    min_loss = float('inf') # 初始min_loss无穷大\n",
    "    patience = 20\n",
    "    early_stop = patience\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        kfold_model.train()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device) # 图像与标签\n",
    "            # print(labels)\n",
    "            # break\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # outputs = model(images)\n",
    "            outputs = kfold_model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels) # 交叉熵损失函数集成了softmax，直接将模型的输出当成参数传入即可，不需要额外的softmax操作（否则报错）\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # _, predicted = torch.max(outputs, 1)\n",
    "            predicted = torch.argmax(outputs, 1) # argmax获得标签，用于计算acc等指标\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_acc = train_correct / train_total\n",
    "        train_acc_history.append(train_acc)\n",
    "\n",
    "\n",
    "            # Validation\n",
    "        kfold_model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_outputs_list = []\n",
    "        val_labels_list = []\n",
    "        y_pred_list = [] # 存储预测的标签\n",
    "        val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                # outputs = model(images)\n",
    "                outputs = kfold_model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # _, predicted = torch.max(outputs, 1)\n",
    "                predicted = torch.argmax(outputs, 1)\n",
    "\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_outputs_list.append(outputs.cpu().numpy())\n",
    "                y_pred_list.append(predicted.cpu().numpy())\n",
    "                val_labels_list.append(labels.cpu().numpy())\n",
    "\n",
    "            val_acc = val_correct / val_total\n",
    "            val_acc_history.append(val_acc)\n",
    "\n",
    "            val_outputs = np.concatenate(val_outputs_list, axis=0)\n",
    "            y_pred = np.concatenate(y_pred_list, axis=0)\n",
    "            val_labels = np.concatenate(val_labels_list, axis=0)\n",
    "            # y_true = np.array(y_true)\n",
    "            # y_pred = np.array(y_pred)\n",
    "            # print(predicted)\n",
    "            # print(y_pred)\n",
    "            # print(val_labels)\n",
    "            # break\n",
    "            \n",
    "\n",
    "            val_fpr, val_tpr, _ = roc_curve(val_labels, val_outputs[:, 1], pos_label=1) # 计算auc，val_outputs[:, 1]表示对正类别的预测概率\n",
    "            val_auc = auc(val_fpr, val_tpr)\n",
    "            val_auc_history.append(val_auc)\n",
    "\n",
    "            val_f1 = f1_score(val_labels, np.argmax(val_outputs, axis=1),average='weighted')\n",
    "            val_f1_history.append(val_f1)\n",
    "\n",
    "            val_r = recall_score(val_labels, np.argmax(val_outputs, axis=1),average='weighted')\n",
    "            val_r_history.append(val_r)\n",
    "\n",
    "            # Calculate average validation loss\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            \n",
    "            if min_loss > avg_val_loss:\n",
    "                min_loss = avg_val_loss\n",
    "                early_stop = patience\n",
    "                \n",
    "                # 验证集损失小的时候指标的值设为最佳\n",
    "                best_acc = val_acc\n",
    "                best_auc = val_auc\n",
    "                best_f1 = val_f1\n",
    "                best_recall = val_r\n",
    "                model_name = 'kfold_' + str(fold+1) + '_model_flair.pth'\n",
    "                torch.save(kfold_model.state_dict(), model_name)\n",
    "                # 在存储最佳模型的同时，利用最佳模型的结果，绘制该折的混淆矩阵\n",
    "                plot_confusion_martix(fold + 1, val_labels, y_pred)\n",
    "            else: # 当前的平均损失比之前epoch的要大\n",
    "                early_stop -= 1\n",
    "\n",
    "            # 当early_stop为0时，结束epoch训练\n",
    "            if early_stop == 0:\n",
    "                break\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}, Val F1: {val_f1:.4f}, Val Recall: {val_r:.4f}, Val Loss: {avg_val_loss:.4f}, Early Stop: {early_stop:.0f}\")\n",
    "   \n",
    "\n",
    "            # print(f\"Epoch {epoch + 1}/{num_epochs}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}, Val F1: {val_f1:.4f}, Val Recall: {val_r:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "            epochs_acc_list.append(val_acc)\n",
    "            epochs_auc_list.append(val_auc)\n",
    "            epochs_f1_list.append(val_f1)\n",
    "            epochs_recall_list.append(val_r)\n",
    "            # 每个epoch验证完成之后，存储验证性能最佳的\n",
    "            # 依据recall的值进行选择，选取此时的指标最为最佳，并存储此时的模型\n",
    "            # if val_auc > best_auc:\n",
    "            #     best_acc = val_acc\n",
    "            #     best_auc = val_auc\n",
    "            #     best_f1 = val_f1\n",
    "            #     best_recall = val_r\n",
    "            #     model_name = 'kfold_' + str(fold+1) + '_model_flair.pth'\n",
    "            #     torch.save(kfold_model.state_dict(), model_name)\n",
    "            #     # 在存储最佳模型的同时，利用最佳模型的结果，绘制该折的混淆矩阵\n",
    "            #     plot_confusion_martix(fold + 1, val_labels, y_pred)\n",
    "            \n",
    "    # 记录验证集的各项指标作为对模型评价的结果\n",
    "    # 不同折训练100个epoch后，计算得到验证的各指标的均值，每一折验证的性能选指标最佳的\n",
    "    # avg_fold_acc = np.mean(epochs_acc_list)\n",
    "    # avg_fold_auc = np.mean(epochs_auc_list)\n",
    "    # avg_fold_f1 = np.mean(epochs_f1_list)\n",
    "    # avg_fold_recall = np.mean(epochs_recall_list)\n",
    "    \n",
    "    # 每一折获得的平均值存储起来\n",
    "    final_acc_list.append(best_acc)\n",
    "    final_auc_list.append(best_auc)\n",
    "    final_f1_list.append(best_f1)\n",
    "    final_recall_list.append(best_recall)\n",
    "    # avg_fold_acc = 0\n",
    "    # avg_fold_auc = 0\n",
    "    # avg_fold_f1 = 0\n",
    "    # val_r = 0\n",
    "    wr.writerow([fold + 1, best_acc, best_auc, best_f1, best_recall])\n",
    "    print(f\"Fold {fold + 1}/{k}, Val Acc: {best_acc:.4f}, Val AUC: {best_auc:.4f}, Val F1: {best_f1:.4f}, avg_fold_recall: {best_recall:.4f}\")\n",
    "    # 绘制训练曲线\n",
    "    plot_train_curve(fold + 1, train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d0e210-444d-4b8c-bce0-793e471e20a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc = np.mean(final_acc_list)\n",
    "auc_score = np.mean(final_auc_list)\n",
    "f1 = np.mean(final_f1_list)\n",
    "recall = np.mean(final_recall_list)\n",
    "print(f\"flair: Accuracy: {acc:.4f}, AUC: {auc_score:.4f}, F1 Score: {f1:.4f}, Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84b145c-4e44-44c5-ad47-11e1a0abdfff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b11cd05-c5a9-4163-8355-4a104ce851ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 跑t1+2mask输入的\n",
    "# 500个epoch，早停点为20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172eeb4d-8d72-4030-b445-d4709265cdb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "data_dir = \"/root/autodl-tmp/project/MedSAM-0.1/data/classfication_t12mask_data\" # 数据存储的根目录\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=transform)\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, \"test\"), transform=transform)\n",
    "\n",
    "# 使用交叉验证，不区分训练集和测试集\n",
    "dataset = ConcatDataset([train_data, test_data])\n",
    "# 加载dataset中的每一项，统计其中的0和1数量，构造出targets数组\n",
    "targets = []\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=64)\n",
    "for images, labels in loader:\n",
    "    targets.append(labels.item())\n",
    "\n",
    "# 在次定义训练曲线绘制函数与混淆矩阵绘制函数\n",
    "def plot_train_curve(kfold ,train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr):\n",
    "    # 传入的参数train acc; val acc; val auc; val f1; val r; val fpr; val tpr\n",
    "    plt.figure()\n",
    "    plt.plot(train_acc_history, label=\"Train Acc\")\n",
    "    plt.plot(val_acc_history, label=\"Val Acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'Acc_curve_of_' + str(kfold) + '_fold_t12mask.png') # 存储acc的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_auc_history, label=\"Val AUC\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'Auc_curve_of_' + str(kfold) + '_fold_t12mask.png') # 存储val auc的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_f1_history, label=\"Val F1\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'F1_curve_of_' + str(kfold) + '_fold_t12mask.png') # 存储val f1的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_r_history, label=\"Val Recall\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Recall\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'Recall_curve_of_' + str(kfold) + '_fold_t12mask.png') # 存储val recall的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(val_fpr, val_tpr, label=f'ROC curve (area = {val_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('./train_curve_images/' + 'ROC_curve_of_' + str(kfold) + '_fold_t12mask.png') # 存储ROC\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_martix(kfold, y_true, y_pred): # 传入的是训练预测得到的标签与真实的标签\n",
    "    # Define class labels\n",
    "    labels = ['HGG','LGG']  # 用您的实际类别标签替换... LGG表示低级别胶质瘤，HGG表示高级别胶质瘤\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure()\n",
    "    sns.heatmap(conf_mat, annot=True, fmt=\".0f\", cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted labels\")\n",
    "    plt.ylabel(\"True labels\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig('./val_confusion_martix_figs/' + 'Confusion_martix_of_' + str(kfold) + '_fold_t12mask.png')\n",
    "    # plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50a6f40-c231-47ee-acc3-9afdb4a21554",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_acc_list = []\n",
    "final_auc_list = []\n",
    "final_f1_list = []\n",
    "final_recall_list = []\n",
    "# 新建一个excel表格。存储每折运行计算得到得指标\n",
    "f = open('result_t12mask.csv', 'a', encoding='utf-8', newline='')\n",
    "wr = csv.writer(f)\n",
    "wr.writerow(['k-fold', 'Val Acc', 'Val AUC', 'Val F1', 'avg_fold_recall']) # csv的标题\n",
    "k = 5 # 改成3折，增大验证的数据集\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=2024)\n",
    "# for fold in range(k):\n",
    "\n",
    "# patience = 10  # 没有性能提升的连续epoch数\n",
    "# wait = 0  # 用于追踪连续没有改善的epoch数\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(range(len(dataset)), targets)):\n",
    "    print(f'Fold {fold + 1}/{k}')\n",
    "    \n",
    "    # 每一折分别记录训练时的指标变化，用于绘制训练曲线\n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "    val_auc_history = []\n",
    "    val_f1_history = []\n",
    "    val_r_history = []\n",
    "\n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    val_dataset = Subset(dataset, val_indices)\n",
    "    \n",
    "    # kfold_model = model # 每折的模型要重置\n",
    "    # 模型重置的时候需要使用深拷贝，不能直接使用赋值语句\n",
    "    kfold_model = copy.deepcopy(model)\n",
    "    kfold_model.to(device)\n",
    "    params_to_update_kfold_model = [] # 对拷贝后的模型，也只更新最后几层\n",
    "    for name, param in kfold_model.named_parameters():\n",
    "        # if name not in ['norm.weight', 'norm.bias', 'head.weight', 'head.bias']: # 只训练最后几层\n",
    "        #     param.requires_grad = False \n",
    "        # else:\n",
    "        #     param.requires_grad = True # 手动设置，不然不会自动赋值\n",
    "        #     params_to_update_kfold_model.append(param)\n",
    "        \n",
    "        # 冻结倒数前30层\n",
    "        if name.find(\"layers.3\") == -1: # 当前层不含layer.3不更新权重\n",
    "            param.requires_grad = False\n",
    "        if name.find(\"layers.3\") == -1 and name not in ['norm.weight', 'norm.bias', 'head.weight', 'head.bias']: #  当前层不含layer.3且name不等于列表中的\n",
    "            param.requires_grad = False\n",
    "        else: # 后30层网络需要训练\n",
    "            param.requires_grad = True # 手动设置，不然不会自动赋值\n",
    "            params_to_update_kfold_model.append(param)\n",
    "        \n",
    "        # print(name)\n",
    "    \n",
    "    # 冻结某些层后，修改optimizer，只更新未冻结的层\n",
    "    optimizer = optim.Adam(params_to_update_kfold_model, lr=1e-4)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=64)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=64)    \n",
    "    \n",
    "    epochs_acc_list = []\n",
    "    epochs_auc_list = []\n",
    "    epochs_f1_list = []\n",
    "    epochs_recall_list = []\n",
    "    best_acc = 0.\n",
    "    best_auc = 0.\n",
    "    best_f1 = 0.\n",
    "    best_recall = 0.\n",
    "    \n",
    "    # best_val_metric = 0  # 初始化最佳验证指标\n",
    "    # early_stopping = False  # 标识是否应该提前停止\n",
    "    \n",
    "    # # 对每一折设置相同规则的早停点\n",
    "    # patience = 10  # 没有性能提升的连续epoch数\n",
    "    # wait = 0  # 用于追踪连续没有改善的epoch数\n",
    "    \n",
    "    # 早停点\n",
    "    min_loss = float('inf') # 初始min_loss无穷大\n",
    "    patience = 20\n",
    "    early_stop = patience\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        kfold_model.train()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device) # 图像与标签\n",
    "            # print(labels)\n",
    "            # break\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # outputs = model(images)\n",
    "            outputs = kfold_model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels) # 交叉熵损失函数集成了softmax，直接将模型的输出当成参数传入即可，不需要额外的softmax操作（否则报错）\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # _, predicted = torch.max(outputs, 1)\n",
    "            predicted = torch.argmax(outputs, 1) # argmax获得标签，用于计算acc等指标\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_acc = train_correct / train_total\n",
    "        train_acc_history.append(train_acc)\n",
    "\n",
    "\n",
    "            # Validation\n",
    "        kfold_model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_outputs_list = []\n",
    "        val_labels_list = []\n",
    "        y_pred_list = [] # 存储预测的标签\n",
    "        val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                # outputs = model(images)\n",
    "                outputs = kfold_model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # _, predicted = torch.max(outputs, 1)\n",
    "                predicted = torch.argmax(outputs, 1)\n",
    "\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_outputs_list.append(outputs.cpu().numpy())\n",
    "                y_pred_list.append(predicted.cpu().numpy())\n",
    "                val_labels_list.append(labels.cpu().numpy())\n",
    "\n",
    "            val_acc = val_correct / val_total\n",
    "            val_acc_history.append(val_acc)\n",
    "\n",
    "            val_outputs = np.concatenate(val_outputs_list, axis=0)\n",
    "            y_pred = np.concatenate(y_pred_list, axis=0)\n",
    "            val_labels = np.concatenate(val_labels_list, axis=0)\n",
    "            # y_true = np.array(y_true)\n",
    "            # y_pred = np.array(y_pred)\n",
    "            # print(predicted)\n",
    "            # print(y_pred)\n",
    "            # print(val_labels)\n",
    "            # break\n",
    "            \n",
    "\n",
    "            val_fpr, val_tpr, _ = roc_curve(val_labels, val_outputs[:, 1], pos_label=1) # 计算auc，val_outputs[:, 1]表示对正类别的预测概率\n",
    "            val_auc = auc(val_fpr, val_tpr)\n",
    "            val_auc_history.append(val_auc)\n",
    "\n",
    "            val_f1 = f1_score(val_labels, np.argmax(val_outputs, axis=1),average='weighted')\n",
    "            val_f1_history.append(val_f1)\n",
    "\n",
    "            val_r = recall_score(val_labels, np.argmax(val_outputs, axis=1),average='weighted')\n",
    "            val_r_history.append(val_r)\n",
    "\n",
    "            # Calculate average validation loss\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            \n",
    "            if min_loss > avg_val_loss:\n",
    "                min_loss = avg_val_loss\n",
    "                early_stop = patience\n",
    "                \n",
    "                # 验证集损失小的时候指标的值设为最佳\n",
    "                best_acc = val_acc\n",
    "                best_auc = val_auc\n",
    "                best_f1 = val_f1\n",
    "                best_recall = val_r\n",
    "                model_name = 'kfold_' + str(fold+1) + '_model_t12mask.pth'\n",
    "                torch.save(kfold_model.state_dict(), model_name)\n",
    "                # 在存储最佳模型的同时，利用最佳模型的结果，绘制该折的混淆矩阵\n",
    "                plot_confusion_martix(fold + 1, val_labels, y_pred)\n",
    "            else: # 当前的平均损失比之前epoch的要大\n",
    "                early_stop -= 1\n",
    "\n",
    "            # 当early_stop为0时，结束epoch训练\n",
    "            if early_stop == 0:\n",
    "                break\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}, Val F1: {val_f1:.4f}, Val Recall: {val_r:.4f}, Val Loss: {avg_val_loss:.4f}, Early Stop: {early_stop:.0f}\")\n",
    "            \n",
    "#                  # 更新最佳验证指标\n",
    "#             if val_r > best_val_metric:\n",
    "#                 best_val_metric = val_r\n",
    "#                 best_acc = val_acc\n",
    "#                 best_auc = val_auc\n",
    "#                 best_f1 = val_f1\n",
    "#                 best_recall = val_r\n",
    "#                 wait = 0  # 重置计数器\n",
    "#              # 保存当前最佳模型\n",
    "#                 model_name = f'kfold_{fold+1}_model_t12mask.pth'\n",
    "#                 torch.save(kfold_model.state_dict(), model_name)\n",
    "#             else:\n",
    "#                 wait += 1  # 没有改善，计数器增加\n",
    "\n",
    "#         # 检查是否应该提前停止\n",
    "#             if wait >= patience:\n",
    "#                 print(f\"Early stopping at epoch {epoch+1}\")\n",
    "#                 break  # 提前终止训练\n",
    "\n",
    "            # print(f\"Epoch {epoch + 1}/{num_epochs}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}, Val F1: {val_f1:.4f}, Val Recall: {val_r:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "            epochs_acc_list.append(val_acc)\n",
    "            epochs_auc_list.append(val_auc)\n",
    "            epochs_f1_list.append(val_f1)\n",
    "            epochs_recall_list.append(val_r)\n",
    "            # 每个epoch验证完成之后，存储验证性能最佳的\n",
    "            # 依据recall的值进行选择，选取此时的指标最为最佳，并存储此时的模型\n",
    "            # if val_auc > best_auc:\n",
    "            #     best_acc = val_acc\n",
    "            #     best_auc = val_auc\n",
    "            #     best_f1 = val_f1\n",
    "            #     best_recall = val_r\n",
    "            #     model_name = 'kfold_' + str(fold+1) + '_model_t12mask.pth'\n",
    "            #     torch.save(kfold_model.state_dict(), model_name)\n",
    "            #     # 在存储最佳模型的同时，利用最佳模型的结果，绘制该折的混淆矩阵\n",
    "            #     plot_confusion_martix(fold + 1, val_labels, y_pred)\n",
    "        \n",
    "    # 记录验证集的各项指标作为对模型评价的结果\n",
    "    # 不同折训练100个epoch后，计算得到验证的各指标的均值，每一折验证的性能选指标最佳的\n",
    "    # avg_fold_acc = np.mean(epochs_acc_list)\n",
    "    # avg_fold_auc = np.mean(epochs_auc_list)\n",
    "    # avg_fold_f1 = np.mean(epochs_f1_list)\n",
    "    # avg_fold_recall = np.mean(epochs_recall_list)\n",
    "    \n",
    "   \n",
    "\n",
    "    # 每一折获得的平均值存储起来\n",
    "    final_acc_list.append(best_acc)\n",
    "    final_auc_list.append(best_auc)\n",
    "    final_f1_list.append(best_f1)\n",
    "    final_recall_list.append(best_recall)\n",
    "    # avg_fold_acc = 0\n",
    "    # avg_fold_auc = 0\n",
    "    # avg_fold_f1 = 0\n",
    "    # val_r = 0\n",
    "    wr.writerow([fold + 1, best_acc, best_auc, best_f1, best_recall])\n",
    "    print(f\"Fold {fold + 1}/{k}, Val Acc: {best_acc:.4f}, Val AUC: {best_auc:.4f}, Val F1: {best_f1:.4f}, avg_fold_recall: {best_recall:.4f}\")\n",
    "    # 绘制训练曲线\n",
    "    plot_train_curve(fold + 1, train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029fe10c-fa65-4847-a99b-14ee644aebf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc = np.mean(final_acc_list)\n",
    "auc_score = np.mean(final_auc_list)\n",
    "f1 = np.mean(final_f1_list)\n",
    "recall = np.mean(final_recall_list)\n",
    "print(f\"t12mask: Accuracy: {acc:.4f}, AUC: {auc_score:.4f}, F1 Score: {f1:.4f}, Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569c2969-703e-4e86-9e95-8db4325dcb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74693ed6-b37b-448f-a450-859e89eaf8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7a7037-2ec3-4890-8fb3-daa6b5dacc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 跑t1+mask+labels输入的\n",
    "# 500epoch 20早停"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d51299-bfbb-4678-b203-cdd900607ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "data_dir = \"/root/autodl-tmp/project/MedSAM-0.1/data/classfication_t1maskseg_data\" # 数据存储的根目录\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=transform)\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, \"test\"), transform=transform)\n",
    "\n",
    "# 使用交叉验证，不区分训练集和测试集\n",
    "dataset = ConcatDataset([train_data, test_data])\n",
    "# 加载dataset中的每一项，统计其中的0和1数量，构造出targets数组\n",
    "targets = []\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=64)\n",
    "for images, labels in loader:\n",
    "    targets.append(labels.item())\n",
    "\n",
    "# 在次定义训练曲线绘制函数与混淆矩阵绘制函数\n",
    "def plot_train_curve(kfold ,train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr):\n",
    "    # 传入的参数train acc; val acc; val auc; val f1; val r; val fpr; val tpr\n",
    "    plt.figure()\n",
    "    plt.plot(train_acc_history, label=\"Train Acc\")\n",
    "    plt.plot(val_acc_history, label=\"Val Acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'Acc_curve_of_' + str(kfold) + '_fold_t1maskseg.png') # 存储acc的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_auc_history, label=\"Val AUC\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'Auc_curve_of_' + str(kfold) + '_fold_t1maskseg.png') # 存储val auc的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_f1_history, label=\"Val F1\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'F1_curve_of_' + str(kfold) + '_fold_t1maskseg.png') # 存储val f1的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_r_history, label=\"Val Recall\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Recall\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'Recall_curve_of_' + str(kfold) + '_fold_t1maskseg.png') # 存储val recall的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(val_fpr, val_tpr, label=f'ROC curve (area = {val_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('./train_curve_images/' + 'ROC_curve_of_' + str(kfold) + '_fold_t1maskseg.png') # 存储ROC\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_martix(kfold, y_true, y_pred): # 传入的是训练预测得到的标签与真实的标签\n",
    "    # Define class labels\n",
    "    labels = ['HGG','LGG']  # 用您的实际类别标签替换... LGG表示低级别胶质瘤，HGG表示高级别胶质瘤\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure()\n",
    "    sns.heatmap(conf_mat, annot=True, fmt=\".0f\", cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted labels\")\n",
    "    plt.ylabel(\"True labels\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig('./val_confusion_martix_figs/' + 'Confusion_martix_of_' + str(kfold) + '_fold_t1maskseg.png')\n",
    "    # plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2df5940-06e3-41d7-8e0e-cbad9c8a4f4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_acc_list = []\n",
    "final_auc_list = []\n",
    "final_f1_list = []\n",
    "final_recall_list = []\n",
    "# 新建一个excel表格。存储每折运行计算得到得指标\n",
    "f = open('result_t1maskseg.csv', 'a', encoding='utf-8', newline='')\n",
    "wr = csv.writer(f)\n",
    "wr.writerow(['k-fold', 'Val Acc', 'Val AUC', 'Val F1', 'avg_fold_recall']) # csv的标题\n",
    "k = 5 # 改成3折，增大验证的数据集\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=2024)\n",
    "# for fold in range(k):\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(range(len(dataset)), targets)):\n",
    "    print(f'Fold {fold + 1}/{k}')\n",
    "    \n",
    "    # 每一折分别记录训练时的指标变化，用于绘制训练曲线\n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "    val_auc_history = []\n",
    "    val_f1_history = []\n",
    "    val_r_history = []\n",
    "\n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    val_dataset = Subset(dataset, val_indices)\n",
    "    \n",
    "    # kfold_model = model # 每折的模型要重置\n",
    "    # 模型重置的时候需要使用深拷贝，不能直接使用赋值语句\n",
    "    kfold_model = copy.deepcopy(model)\n",
    "    kfold_model.to(device)\n",
    "    params_to_update_kfold_model = [] # 对拷贝后的模型，也只更新最后几层\n",
    "    for name, param in kfold_model.named_parameters():\n",
    "        # if name not in ['norm.weight', 'norm.bias', 'head.weight', 'head.bias']: # 只训练最后几层\n",
    "        #     param.requires_grad = False \n",
    "        # else:\n",
    "        #     param.requires_grad = True # 手动设置，不然不会自动赋值\n",
    "        #     params_to_update_kfold_model.append(param)\n",
    "            \n",
    "        # 冻结倒数前30层\n",
    "        if name.find(\"layers.3\") == -1: # 当前层不含layer.3不更新权重\n",
    "            param.requires_grad = False\n",
    "        if name.find(\"layers.3\") == -1 and name not in ['norm.weight', 'norm.bias', 'head.weight', 'head.bias']: #  当前层不含layer.3且name不等于列表中的\n",
    "            param.requires_grad = False\n",
    "        else: # 后30层网络需要训练\n",
    "            param.requires_grad = True # 手动设置，不然不会自动赋值\n",
    "            params_to_update_kfold_model.append(param)\n",
    "        # print(name)\n",
    "    \n",
    "    # 冻结某些层后，修改optimizer，只更新未冻结的层\n",
    "    optimizer = optim.Adam(params_to_update_kfold_model, lr=1e-4)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=64)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=64)    \n",
    "    \n",
    "    epochs_acc_list = []\n",
    "    epochs_auc_list = []\n",
    "    epochs_f1_list = []\n",
    "    epochs_recall_list = []\n",
    "    best_acc = 0.\n",
    "    best_auc = 0.\n",
    "    best_f1 = 0.\n",
    "    best_recall = 0.\n",
    "    \n",
    "    # 早停点\n",
    "    min_loss = float('inf') # 初始min_loss无穷大\n",
    "    patience = 20\n",
    "    early_stop = patience\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        kfold_model.train()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device) # 图像与标签\n",
    "            # print(labels)\n",
    "            # break\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # outputs = model(images)\n",
    "            outputs = kfold_model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels) # 交叉熵损失函数集成了softmax，直接将模型的输出当成参数传入即可，不需要额外的softmax操作（否则报错）\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # _, predicted = torch.max(outputs, 1)\n",
    "            predicted = torch.argmax(outputs, 1) # argmax获得标签，用于计算acc等指标\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_acc = train_correct / train_total\n",
    "        train_acc_history.append(train_acc)\n",
    "\n",
    "\n",
    "            # Validation\n",
    "        kfold_model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_outputs_list = []\n",
    "        val_labels_list = []\n",
    "        y_pred_list = [] # 存储预测的标签\n",
    "        val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                # outputs = model(images)\n",
    "                outputs = kfold_model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # _, predicted = torch.max(outputs, 1)\n",
    "                predicted = torch.argmax(outputs, 1)\n",
    "\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_outputs_list.append(outputs.cpu().numpy())\n",
    "                y_pred_list.append(predicted.cpu().numpy())\n",
    "                val_labels_list.append(labels.cpu().numpy())\n",
    "\n",
    "            val_acc = val_correct / val_total\n",
    "            val_acc_history.append(val_acc)\n",
    "\n",
    "            val_outputs = np.concatenate(val_outputs_list, axis=0)\n",
    "            y_pred = np.concatenate(y_pred_list, axis=0)\n",
    "            val_labels = np.concatenate(val_labels_list, axis=0)\n",
    "            # y_true = np.array(y_true)\n",
    "            # y_pred = np.array(y_pred)\n",
    "            # print(predicted)\n",
    "            # print(y_pred)\n",
    "            # print(val_labels)\n",
    "            # break\n",
    "            \n",
    "\n",
    "            val_fpr, val_tpr, _ = roc_curve(val_labels, val_outputs[:, 1], pos_label=1) # 计算auc，val_outputs[:, 1]表示对正类别的预测概率\n",
    "            val_auc = auc(val_fpr, val_tpr)\n",
    "            val_auc_history.append(val_auc)\n",
    "\n",
    "            val_f1 = f1_score(val_labels, np.argmax(val_outputs, axis=1),average='weighted')\n",
    "            val_f1_history.append(val_f1)\n",
    "\n",
    "            val_r = recall_score(val_labels, np.argmax(val_outputs, axis=1),average='weighted')\n",
    "            val_r_history.append(val_r)\n",
    "\n",
    "            # Calculate average validation loss\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            \n",
    "            if min_loss > avg_val_loss:\n",
    "                min_loss = avg_val_loss\n",
    "                early_stop = patience\n",
    "                \n",
    "                # 验证集损失小的时候指标的值设为最佳\n",
    "                best_acc = val_acc\n",
    "                best_auc = val_auc\n",
    "                best_f1 = val_f1\n",
    "                best_recall = val_r\n",
    "                model_name = 'kfold_' + str(fold+1) + '_model_t1maskseg.pth'\n",
    "                torch.save(kfold_model.state_dict(), model_name)\n",
    "                # 在存储最佳模型的同时，利用最佳模型的结果，绘制该折的混淆矩阵\n",
    "                plot_confusion_martix(fold + 1, val_labels, y_pred)\n",
    "            else: # 当前的平均损失比之前epoch的要大\n",
    "                early_stop -= 1\n",
    "\n",
    "            # 当early_stop为0时，结束epoch训练\n",
    "            if early_stop == 0:\n",
    "                break\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}, Val F1: {val_f1:.4f}, Val Recall: {val_r:.4f}, Val Loss: {avg_val_loss:.4f}, Early Stop: {early_stop:.0f}\")\n",
    "            \n",
    "            # print(f\"Epoch {epoch + 1}/{num_epochs}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}, Val F1: {val_f1:.4f}, Val Recall: {val_r:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "            epochs_acc_list.append(val_acc)\n",
    "            epochs_auc_list.append(val_auc)\n",
    "            epochs_f1_list.append(val_f1)\n",
    "            epochs_recall_list.append(val_r)\n",
    "            # 每个epoch验证完成之后，存储验证性能最佳的\n",
    "            # 依据recall的值进行选择，选取此时的指标最为最佳，并存储此时的模型\n",
    "            # if val_auc > best_auc:\n",
    "            #     best_acc = val_acc\n",
    "            #     best_auc = val_auc\n",
    "            #     best_f1 = val_f1\n",
    "            #     best_recall = val_r\n",
    "            #     model_name = 'kfold_' + str(fold+1) + '_model_t1maskseg.pth'\n",
    "            #     torch.save(kfold_model.state_dict(), model_name)\n",
    "            #     # 在存储最佳模型的同时，利用最佳模型的结果，绘制该折的混淆矩阵\n",
    "            #     plot_confusion_martix(fold + 1, val_labels, y_pred)\n",
    "            \n",
    "    # 记录验证集的各项指标作为对模型评价的结果\n",
    "    # 不同折训练100个epoch后，计算得到验证的各指标的均值，每一折验证的性能选指标最佳的\n",
    "    # avg_fold_acc = np.mean(epochs_acc_list)\n",
    "    # avg_fold_auc = np.mean(epochs_auc_list)\n",
    "    # avg_fold_f1 = np.mean(epochs_f1_list)\n",
    "    # avg_fold_recall = np.mean(epochs_recall_list)\n",
    "    \n",
    "    # 每一折获得的平均值存储起来\n",
    "    final_acc_list.append(best_acc)\n",
    "    final_auc_list.append(best_auc)\n",
    "    final_f1_list.append(best_f1)\n",
    "    final_recall_list.append(best_recall)\n",
    "    # avg_fold_acc = 0\n",
    "    # avg_fold_auc = 0\n",
    "    # avg_fold_f1 = 0\n",
    "    # val_r = 0\n",
    "    wr.writerow([fold + 1, best_acc, best_auc, best_f1, best_recall])\n",
    "    print(f\"Fold {fold + 1}/{k}, Val Acc: {best_acc:.4f}, Val AUC: {best_auc:.4f}, Val F1: {best_f1:.4f}, avg_fold_recall: {best_recall:.4f}\")\n",
    "    # 绘制训练曲线\n",
    "    plot_train_curve(fold + 1, train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a75f6f-1179-4346-acb4-4d11566f76a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc = np.mean(final_acc_list)\n",
    "auc_score = np.mean(final_auc_list)\n",
    "f1 = np.mean(final_f1_list)\n",
    "recall = np.mean(final_recall_list)\n",
    "print(f\"t1maskseg: Accuracy: {acc:.4f}, AUC: {auc_score:.4f}, F1 Score: {f1:.4f}, Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd01a41c-c688-4ff4-bdf8-79f90125f061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aab3a2-c3cf-46f6-a831-4e35c2cc4d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flair t1 mask作为输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a62aea-5922-4727-9f00-de1e457ef348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "data_dir = \"/root/autodl-tmp/project/MedSAM-0.1/data/classfication_t1flairmask_data\" # 数据存储的根目录\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=transform)\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, \"test\"), transform=transform)\n",
    "\n",
    "# 使用交叉验证，不区分训练集和测试集\n",
    "dataset = ConcatDataset([train_data, test_data])\n",
    "# 加载dataset中的每一项，统计其中的0和1数量，构造出targets数组\n",
    "targets = []\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=64)\n",
    "for images, labels in loader:\n",
    "    targets.append(labels.item())\n",
    "\n",
    "# 在次定义训练曲线绘制函数与混淆矩阵绘制函数\n",
    "def plot_train_curve(kfold ,train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr):\n",
    "    # 传入的参数train acc; val acc; val auc; val f1; val r; val fpr; val tpr\n",
    "    plt.figure()\n",
    "    plt.plot(train_acc_history, label=\"Train Acc\")\n",
    "    plt.plot(val_acc_history, label=\"Val Acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'Acc_curve_of_' + str(kfold) + '_fold_t1flairmask.png') # 存储acc的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_auc_history, label=\"Val AUC\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'Auc_curve_of_' + str(kfold) + '_fold_t1flairmask.png') # 存储val auc的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_f1_history, label=\"Val F1\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'F1_curve_of_' + str(kfold) + '_fold_t1flairmask.png') # 存储val f1的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(val_r_history, label=\"Val Recall\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Recall\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./train_curve_images/' + 'Recall_curve_of_' + str(kfold) + '_fold_t1flairmask.png') # 存储val recall的训练曲线\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(val_fpr, val_tpr, label=f'ROC curve (area = {val_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('./train_curve_images/' + 'ROC_curve_of_' + str(kfold) + '_fold_t1flairmask.png') # 存储ROC\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_martix(kfold, y_true, y_pred): # 传入的是训练预测得到的标签与真实的标签\n",
    "    # Define class labels\n",
    "    labels = ['HGG','LGG']  # 用您的实际类别标签替换... LGG表示低级别胶质瘤，HGG表示高级别胶质瘤\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure()\n",
    "    sns.heatmap(conf_mat, annot=True, fmt=\".0f\", cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted labels\")\n",
    "    plt.ylabel(\"True labels\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig('./val_confusion_martix_figs/' + 'Confusion_martix_of_' + str(kfold) + '_fold_t1flairmask.png')\n",
    "    # plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6680c72-0d11-41ee-aaa3-049767192c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_acc_list = []\n",
    "final_auc_list = []\n",
    "final_f1_list = []\n",
    "final_recall_list = []\n",
    "# 新建一个excel表格。存储每折运行计算得到得指标\n",
    "f = open('result_t1flairmask.csv', 'a', encoding='utf-8', newline='')\n",
    "wr = csv.writer(f)\n",
    "wr.writerow(['k-fold', 'Val Acc', 'Val AUC', 'Val F1', 'avg_fold_recall']) # csv的标题\n",
    "k = 5 # 改成3折，增大验证的数据集\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=2024)\n",
    "# for fold in range(k):\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(range(len(dataset)), targets)):\n",
    "    print(f'Fold {fold + 1}/{k}')\n",
    "    \n",
    "    # 每一折分别记录训练时的指标变化，用于绘制训练曲线\n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "    val_auc_history = []\n",
    "    val_f1_history = []\n",
    "    val_r_history = []\n",
    "\n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    val_dataset = Subset(dataset, val_indices)\n",
    "    \n",
    "    # kfold_model = model # 每折的模型要重置\n",
    "    # 模型重置的时候需要使用深拷贝，不能直接使用赋值语句\n",
    "    kfold_model = copy.deepcopy(model)\n",
    "    kfold_model.to(device)\n",
    "    params_to_update_kfold_model = [] # 对拷贝后的模型，也只更新最后几层\n",
    "    for name, param in kfold_model.named_parameters():\n",
    "        # if name not in ['norm.weight', 'norm.bias', 'head.weight', 'head.bias']: # 只训练最后几层\n",
    "        #     param.requires_grad = False \n",
    "        # else:\n",
    "        #     param.requires_grad = True # 手动设置，不然不会自动赋值\n",
    "        #     params_to_update_kfold_model.append(param)\n",
    "            \n",
    "        # 冻结倒数前30层\n",
    "        if name.find(\"layers.3\") == -1: # 当前层不含layer.3不更新权重\n",
    "            param.requires_grad = False\n",
    "        if name.find(\"layers.3\") == -1 and name not in ['norm.weight', 'norm.bias', 'head.weight', 'head.bias']: #  当前层不含layer.3且name不等于列表中的\n",
    "            param.requires_grad = False\n",
    "        else: # 后30层网络需要训练\n",
    "            param.requires_grad = True # 手动设置，不然不会自动赋值\n",
    "            params_to_update_kfold_model.append(param)\n",
    "        # print(name)\n",
    "    \n",
    "    # 冻结某些层后，修改optimizer，只更新未冻结的层\n",
    "    optimizer = optim.Adam(params_to_update_kfold_model, lr=1e-4)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=64)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=64)    \n",
    "    \n",
    "    epochs_acc_list = []\n",
    "    epochs_auc_list = []\n",
    "    epochs_f1_list = []\n",
    "    epochs_recall_list = []\n",
    "    best_acc = 0.\n",
    "    best_auc = 0.\n",
    "    best_f1 = 0.\n",
    "    best_recall = 0.\n",
    "    \n",
    "    # 早停点\n",
    "    min_loss = float('inf') # 初始min_loss无穷大\n",
    "    patience = 20\n",
    "    early_stop = patience\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        kfold_model.train()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device) # 图像与标签\n",
    "            # print(labels)\n",
    "            # break\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # outputs = model(images)\n",
    "            outputs = kfold_model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels) # 交叉熵损失函数集成了softmax，直接将模型的输出当成参数传入即可，不需要额外的softmax操作（否则报错）\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # _, predicted = torch.max(outputs, 1)\n",
    "            predicted = torch.argmax(outputs, 1) # argmax获得标签，用于计算acc等指标\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_acc = train_correct / train_total\n",
    "        train_acc_history.append(train_acc)\n",
    "\n",
    "\n",
    "            # Validation\n",
    "        kfold_model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_outputs_list = []\n",
    "        val_labels_list = []\n",
    "        y_pred_list = [] # 存储预测的标签\n",
    "        val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                # outputs = model(images)\n",
    "                outputs = kfold_model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # _, predicted = torch.max(outputs, 1)\n",
    "                predicted = torch.argmax(outputs, 1)\n",
    "\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_outputs_list.append(outputs.cpu().numpy())\n",
    "                y_pred_list.append(predicted.cpu().numpy())\n",
    "                val_labels_list.append(labels.cpu().numpy())\n",
    "\n",
    "            val_acc = val_correct / val_total\n",
    "            val_acc_history.append(val_acc)\n",
    "\n",
    "            val_outputs = np.concatenate(val_outputs_list, axis=0)\n",
    "            y_pred = np.concatenate(y_pred_list, axis=0)\n",
    "            val_labels = np.concatenate(val_labels_list, axis=0)\n",
    "            # y_true = np.array(y_true)\n",
    "            # y_pred = np.array(y_pred)\n",
    "            # print(predicted)\n",
    "            # print(y_pred)\n",
    "            # print(val_labels)\n",
    "            # break\n",
    "            \n",
    "\n",
    "            val_fpr, val_tpr, _ = roc_curve(val_labels, val_outputs[:, 1], pos_label=1) # 计算auc，val_outputs[:, 1]表示对正类别的预测概率\n",
    "            val_auc = auc(val_fpr, val_tpr)\n",
    "            val_auc_history.append(val_auc)\n",
    "\n",
    "            val_f1 = f1_score(val_labels, np.argmax(val_outputs, axis=1),average='weighted')\n",
    "            val_f1_history.append(val_f1)\n",
    "\n",
    "            val_r = recall_score(val_labels, np.argmax(val_outputs, axis=1),average='weighted')\n",
    "            val_r_history.append(val_r)\n",
    "\n",
    "            # Calculate average validation loss\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            \n",
    "            if min_loss > avg_val_loss:\n",
    "                min_loss = avg_val_loss\n",
    "                early_stop = patience\n",
    "                \n",
    "                # 验证集损失小的时候指标的值设为最佳\n",
    "                best_acc = val_acc\n",
    "                best_auc = val_auc\n",
    "                best_f1 = val_f1\n",
    "                best_recall = val_r\n",
    "                model_name = 'kfold_' + str(fold+1) + '_model_t1flairmask.pth'\n",
    "                torch.save(kfold_model.state_dict(), model_name)\n",
    "                # 在存储最佳模型的同时，利用最佳模型的结果，绘制该折的混淆矩阵\n",
    "                plot_confusion_martix(fold + 1, val_labels, y_pred)\n",
    "            else: # 当前的平均损失比之前epoch的要大\n",
    "                early_stop -= 1\n",
    "\n",
    "            # 当early_stop为0时，结束epoch训练\n",
    "            if early_stop == 0:\n",
    "                break\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}, Val F1: {val_f1:.4f}, Val Recall: {val_r:.4f}, Val Loss: {avg_val_loss:.4f}, Early Stop: {early_stop:.0f}\")\n",
    "            \n",
    "            # print(f\"Epoch {epoch + 1}/{num_epochs}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}, Val F1: {val_f1:.4f}, Val Recall: {val_r:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "            epochs_acc_list.append(val_acc)\n",
    "            epochs_auc_list.append(val_auc)\n",
    "            epochs_f1_list.append(val_f1)\n",
    "            epochs_recall_list.append(val_r)\n",
    "            # 每个epoch验证完成之后，存储验证性能最佳的\n",
    "            # 依据recall的值进行选择，选取此时的指标最为最佳，并存储此时的模型\n",
    "            # if val_auc > best_auc:\n",
    "            #     best_acc = val_acc\n",
    "            #     best_auc = val_auc\n",
    "            #     best_f1 = val_f1\n",
    "            #     best_recall = val_r\n",
    "            #     model_name = 'kfold_' + str(fold+1) + '_model_t1maskseg.pth'\n",
    "            #     torch.save(kfold_model.state_dict(), model_name)\n",
    "            #     # 在存储最佳模型的同时，利用最佳模型的结果，绘制该折的混淆矩阵\n",
    "            #     plot_confusion_martix(fold + 1, val_labels, y_pred)\n",
    "            \n",
    "    # 记录验证集的各项指标作为对模型评价的结果\n",
    "    # 不同折训练100个epoch后，计算得到验证的各指标的均值，每一折验证的性能选指标最佳的\n",
    "    # avg_fold_acc = np.mean(epochs_acc_list)\n",
    "    # avg_fold_auc = np.mean(epochs_auc_list)\n",
    "    # avg_fold_f1 = np.mean(epochs_f1_list)\n",
    "    # avg_fold_recall = np.mean(epochs_recall_list)\n",
    "    \n",
    "    # 每一折获得的平均值存储起来\n",
    "    final_acc_list.append(best_acc)\n",
    "    final_auc_list.append(best_auc)\n",
    "    final_f1_list.append(best_f1)\n",
    "    final_recall_list.append(best_recall)\n",
    "    # avg_fold_acc = 0\n",
    "    # avg_fold_auc = 0\n",
    "    # avg_fold_f1 = 0\n",
    "    # val_r = 0\n",
    "    wr.writerow([fold + 1, best_acc, best_auc, best_f1, best_recall])\n",
    "    print(f\"Fold {fold + 1}/{k}, Val Acc: {best_acc:.4f}, Val AUC: {best_auc:.4f}, Val F1: {best_f1:.4f}, avg_fold_recall: {best_recall:.4f}\")\n",
    "    # 绘制训练曲线\n",
    "    plot_train_curve(fold + 1, train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6d9f88-0f74-4beb-96a9-0f7366f53ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc = np.mean(final_acc_list)\n",
    "auc_score = np.mean(final_auc_list)\n",
    "f1 = np.mean(final_f1_list)\n",
    "recall = np.mean(final_recall_list)\n",
    "print(f\"t1flairmask: Accuracy: {acc:.4f}, AUC: {auc_score:.4f}, F1 Score: {f1:.4f}, Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007e7f56-9399-4fd3-937f-c52fd03e1032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80592780-33a9-4f16-b093-0b7be6d3c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### \n",
    "##### 以下代码不用运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15d553c-76c4-4dc0-9726-594ed4275f85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_acc_history, label=\"Train Acc\")\n",
    "plt.plot(val_acc_history, label=\"Val Acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(val_auc_history, label=\"Val AUC\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(val_f1_history, label=\"Val F1\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(val_r_history, label=\"Val Recall\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(val_fpr, val_tpr, label=f'ROC curve (area = {val_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f384448-0566-449a-8f80-7a940b367203",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, f1_score, recall_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49e5ff7-345e-4e97-8fa6-aa4522538569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a data loader for the images\n",
    "import torch.nn.functional as F\n",
    "data_dir = \"/root/autodl-tmp/project/MedSAM-0.1/data/classfication_data/test\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "image_data = datasets.ImageFolder(data_dir, transform=transform)\n",
    "data_loader = DataLoader(image_data, batch_size=1, shuffle=False)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        probabilities = F.softmax(outputs, dim=1)  # 使用softmax函数进行概率化处理\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.append(labels.item())\n",
    "        y_pred.append(predicted.item())\n",
    "        y_scores.append(probabilities.cpu().numpy())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "y_scores = np.concatenate(y_scores, axis=0)\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "auc_score = roc_auc_score(y_true, y_scores[:, 1], multi_class='ovo')\n",
    "f1 = f1_score(y_true, y_pred,average='weighted')\n",
    "recall = recall_score(y_true, y_pred,average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}, AUC: {auc_score:.4f}, F1 Score: {f1:.4f}, Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba71056a-b475-4d5b-966d-37bed9f4814c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa507b0a-6e70-4a36-a146-97e793ef22ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a data loader for the images\n",
    "import torch.nn.functional as F\n",
    "data_dir = \"/root/autodl-tmp/project/MedSAM-0.1/data/classfication_data/train\" # 训练集\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "image_data = datasets.ImageFolder(data_dir, transform=transform)\n",
    "data_loader = DataLoader(image_data, batch_size=1, shuffle=False)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_true1 = []\n",
    "y_pred1 = []\n",
    "y_scores1 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        probabilities = F.softmax(outputs, dim=1)  # 使用softmax函数进行概率化处理\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true1.append(labels.item())\n",
    "        y_pred1.append(predicted.item())\n",
    "        y_scores1.append(probabilities.cpu().numpy())\n",
    "\n",
    "y_true1 = np.array(y_true1)\n",
    "y_pred1 = np.array(y_pred1)\n",
    "y_scores1 = np.concatenate(y_scores1, axis=0)\n",
    "\n",
    "acc1 = accuracy_score(y_true1, y_pred1)\n",
    "auc_score1 = roc_auc_score(y_true1, y_scores1, multi_class='ovo')\n",
    "f11 = f1_score(y_true1, y_pred1,average='weighted')\n",
    "recall1 = recall_score(y_true1, y_pred1,average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {acc1:.4f}, AUC: {auc_score1:.4f}, F1 Score: {f11:.4f}, Recall: {recall1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b9b7f0-e497-4efa-94ab-415ac199f2a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Define class labels\n",
    "labels = ['HGG','LGG']  # 用您的实际类别标签替换...\n",
    "\n",
    "# Plot confusion matrix\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "plt.figure()\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\".0f\", cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a5878c-8b43-4f4b-93dd-bf5438fbbeb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
